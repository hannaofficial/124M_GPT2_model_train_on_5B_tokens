{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMKafKqhhu9VnCVH3MhbBuh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "72eb92756883492fbff632db7a37ffe3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d127416c462f47c6bbea1478cfb8244c",
              "IPY_MODEL_654a9d6f21824c7b88492f74fc224343",
              "IPY_MODEL_43dde6a2500a4dd38cc6f20949a6b653"
            ],
            "layout": "IPY_MODEL_bc9e3b5e7a3b4ee58c33982e27b02b75"
          }
        },
        "d127416c462f47c6bbea1478cfb8244c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_90354aa6ae7845fcb38dce3fb2396dfa",
            "placeholder": "​",
            "style": "IPY_MODEL_d6f6c94a4d8d4f9d83da0b96e49872c4",
            "value": "README.md: 100%"
          }
        },
        "654a9d6f21824c7b88492f74fc224343": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_04ab619ea18a40d1bf4d4cb3f772704f",
            "max": 23277,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f8fce0a0524a43e1ae2625a337243c23",
            "value": 23277
          }
        },
        "43dde6a2500a4dd38cc6f20949a6b653": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bfcea379963e423f9a3c3541d4c3fda3",
            "placeholder": "​",
            "style": "IPY_MODEL_5534c414ff654e99b029ee16a85da514",
            "value": " 23.3k/23.3k [00:00&lt;00:00, 1.41MB/s]"
          }
        },
        "bc9e3b5e7a3b4ee58c33982e27b02b75": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "90354aa6ae7845fcb38dce3fb2396dfa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d6f6c94a4d8d4f9d83da0b96e49872c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "04ab619ea18a40d1bf4d4cb3f772704f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f8fce0a0524a43e1ae2625a337243c23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bfcea379963e423f9a3c3541d4c3fda3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5534c414ff654e99b029ee16a85da514": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "60846c71809c48afaa340e4dc6d11c16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e21e2e352bb24139a5b87e5509e4ca47",
              "IPY_MODEL_a6682e6a924a41dbbc89c1b2f90d908f",
              "IPY_MODEL_802ab76421934bb99e37e94d02f983d7"
            ],
            "layout": "IPY_MODEL_616320ea109f4e8093cc7a5452996b35"
          }
        },
        "e21e2e352bb24139a5b87e5509e4ca47": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_39d274d2e0694c2483845a47a885ea56",
            "placeholder": "​",
            "style": "IPY_MODEL_0a1e62eed56649a7a718b628d0b96551",
            "value": "000_00000.parquet: 100%"
          }
        },
        "a6682e6a924a41dbbc89c1b2f90d908f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_875ad1b94dbb4a538efa376b3186c8a3",
            "max": 2152819114,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2cdbb8d78f4b4662802705cb7fb5965f",
            "value": 2152819114
          }
        },
        "802ab76421934bb99e37e94d02f983d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4c7f8fedab38463c8695ca2d082ae46f",
            "placeholder": "​",
            "style": "IPY_MODEL_8a6201f9eb514534bd168464f3b5d361",
            "value": " 2.15G/2.15G [00:50&lt;00:00, 42.4MB/s]"
          }
        },
        "616320ea109f4e8093cc7a5452996b35": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "39d274d2e0694c2483845a47a885ea56": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0a1e62eed56649a7a718b628d0b96551": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "875ad1b94dbb4a538efa376b3186c8a3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2cdbb8d78f4b4662802705cb7fb5965f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4c7f8fedab38463c8695ca2d082ae46f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8a6201f9eb514534bd168464f3b5d361": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4832b38e6b44477eb063c05993741ff3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ad9893768199402ba0db13f3129d3519",
              "IPY_MODEL_ee9e2eac426c4fb387cf4e0c320cc7df",
              "IPY_MODEL_bd1a06d70b6444f78bcf0c56fe8c8ba0"
            ],
            "layout": "IPY_MODEL_4768666c04b64585b5bac800e538710e"
          }
        },
        "ad9893768199402ba0db13f3129d3519": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6d420534d491446b98eccc9a107389aa",
            "placeholder": "​",
            "style": "IPY_MODEL_bd61488123a246d2ac8da5e8aa169108",
            "value": "001_00000.parquet: 100%"
          }
        },
        "ee9e2eac426c4fb387cf4e0c320cc7df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c4571d99446b41e6859af1b9f0440d01",
            "max": 2152222432,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3de38dceb3a34a59923c9b73223a14fd",
            "value": 2152222432
          }
        },
        "bd1a06d70b6444f78bcf0c56fe8c8ba0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1f6c449dff414eca83d9229652202fdc",
            "placeholder": "​",
            "style": "IPY_MODEL_f078c886373a4f2c9b30473a23b862ad",
            "value": " 2.15G/2.15G [00:50&lt;00:00, 41.8MB/s]"
          }
        },
        "4768666c04b64585b5bac800e538710e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d420534d491446b98eccc9a107389aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd61488123a246d2ac8da5e8aa169108": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c4571d99446b41e6859af1b9f0440d01": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3de38dceb3a34a59923c9b73223a14fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1f6c449dff414eca83d9229652202fdc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f078c886373a4f2c9b30473a23b862ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8c6afa49f98340c893bd2a3f41420a0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ed357ee222774f778bca0e3f9600693d",
              "IPY_MODEL_6591a004e16a4151a892a511ef2927cd",
              "IPY_MODEL_641c75c3ab6a4afbb4d71a5c8bf9cc94"
            ],
            "layout": "IPY_MODEL_8cc6ae667445469ba86db8d2d2d9c61f"
          }
        },
        "ed357ee222774f778bca0e3f9600693d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_46bdefba2ea24daabcf48b8762393fb9",
            "placeholder": "​",
            "style": "IPY_MODEL_4de0e0982d874540b2bada5aa570b0ef",
            "value": "Generating train split: "
          }
        },
        "6591a004e16a4151a892a511ef2927cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_62431d1974ef4eb8b5f67006de3d9a4e",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e773e6f080924ac58f8f0672dfed145a",
            "value": 1
          }
        },
        "641c75c3ab6a4afbb4d71a5c8bf9cc94": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f40212cc39e94be08cfc375204e8334e",
            "placeholder": "​",
            "style": "IPY_MODEL_cfbfcd3861ce43cfa98957d1188b7a25",
            "value": " 1455000/0 [00:31&lt;00:00, 44617.60 examples/s]"
          }
        },
        "8cc6ae667445469ba86db8d2d2d9c61f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "46bdefba2ea24daabcf48b8762393fb9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4de0e0982d874540b2bada5aa570b0ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "62431d1974ef4eb8b5f67006de3d9a4e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "e773e6f080924ac58f8f0672dfed145a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f40212cc39e94be08cfc375204e8334e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cfbfcd3861ce43cfa98957d1188b7a25": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hannaofficial/124M_GPT2_model_train_on_5B_tokens/blob/main/GPT3_124M_parameters_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "paper to read  https://arxiv.org/pdf/2205.14135.pdf"
      ],
      "metadata": {
        "id": "BjPPvvNPFZqq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "```\n",
        "* Read gpt 2 gpt 3 paper finished\n",
        "* flash attention\n",
        "* fine web edu research paper\n",
        "* Eleuther evaluation harness\n",
        "* Fine tune for chatting (llama paper)\n",
        "```\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "JX8fVnoU4UbM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "  GPT 3 used sparse attention(a sentence is not attented or dot product will all\n",
        "  words in the sentences) this technique was used to reduce computational\n",
        "  efficience from (N^2 to N.k). I used here full attention (N^2) because I was\n",
        "  using 124m parameter i.e. small model size. and for now don't want to go in that complexity.\n",
        "  Because my next project will be on building llama model from scrach there\n",
        "  they use other attention mecchanism. I wanted to used that directly.\n",
        "\n",
        "  All the rest of the model are same as GPT3 as state in there paper\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "DhdukL7WyXcN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p9ON2VdiNQ13"
      },
      "outputs": [],
      "source": [
        "from dataclasses import dataclass\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "import math\n",
        "import inspect\n",
        "import code"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cpu\")\n",
        "if torch.cuda.is_available():\n",
        "  device = torch.device(\"cuda\")\n",
        "\n",
        "\n",
        "print(f\"using device: {device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OrCv57jY4i4W",
        "outputId": "250687eb-7fe2-456b-c777-6d9382c3741b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os"
      ],
      "metadata": {
        "id": "878LgFTm-xs0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "if you have more than one gpu you can work it together for fast training"
      ],
      "metadata": {
        "id": "K4nlP91KA26z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        " if more than one GPU available\n",
        " then use this command to run the code\n",
        " torchrun --standalone --nproc_per_node=2  /* here 2 means we have two gpu available*/ gpt2.py\n",
        "```"
      ],
      "metadata": {
        "id": "1kdAWE5-ClGn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.distributed import init_process_group, destroy_process_group\n",
        "\n",
        "#set up DDP (distributed data parrallel)\n",
        "#trochrun command set the env varable RANK, LOCALRANK and WORLD SIZE\n",
        "ddp = int(os.environ.get('RANK',-1)) != -1\n",
        "if ddp:\n",
        "  assert torch.cuda.is_available(), 'for now i think we need cuda'\n",
        "  init_process_group(backend='nccl')\n",
        "  ddp_rank = int(os.environ['RANK'])  #identification of each gpu\n",
        "  ddp_local_rank = int(os.environ['LOCAL_RANK'])  #rank of the gpu on single node\n",
        "  ddp_world_size = int(os.environ['WORLD_SIZE'])  #total num of processes/gpu running\n",
        "  device = f'cuda:{ddp_local_rank}'\n",
        "  torch.cuda.set_device(device)\n",
        "  master_process = ddp_rank == 0\n",
        "else:\n",
        "  #vanilla, non-DDP run\n",
        "  ddp_rank = 0\n",
        "  ddp_local_rank = 0\n",
        "  ddp_world_size = 1\n",
        "  master_process = True\n",
        "  #attempt to autodetect device\n",
        "  device = \"cpu\"\n",
        "  if torch.cuda.is_available():\n",
        "    device = \"cuda\"\n",
        "  elif hasattr(torch.backends, \"mps\") and torch.backends.mps.is_available():\n",
        "    device = \"mps\"\n",
        "  print(f\"using device: {device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QQV3552Z-v_F",
        "outputId": "2ed823f5-0b22-43d5-cc3c-30554085d0d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "5S17MovfA16R",
        "outputId": "f903da85-2b8a-470c-d96b-741940e302ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "88L630sg59mQ",
        "outputId": "d400d38a-7999-4c69-841e-4998b6b88842"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Nov  3 06:56:08 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   67C    P8              10W /  70W |      3MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Linear means y =  x*w**t + bias and nn.Linear(3,4)  in put dimension 3 output dimension 4"
      ],
      "metadata": {
        "id": "q8ngFZtiyFOF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#GPT MODEL CODE"
      ],
      "metadata": {
        "id": "pU33iAwDjZ8E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NewGELU(nn.Module):\n",
        "    \"\"\"Careful there are a few versions of GeLU, this one is the exact one used by OpenAI\"\"\"\n",
        "    def forward(self, input):\n",
        "        return 0.5 * input * (1.0 + torch.tanh(math.sqrt(2.0 / math.pi) * (input + 0.044715 * torch.pow(input, 3.0))))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class CausalSelfAttention(nn.Module):\n",
        "\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        assert config.n_embd % config.n_head == 0\n",
        "        # key, query, value projections for all heads, but in a batch\n",
        "        self.c_attn = nn.Linear(config.n_embd, 3 * config.n_embd)\n",
        "        # output projection\n",
        "        self.c_proj = nn.Linear(config.n_embd, config.n_embd)\n",
        "        self.c_proj.NANOGPT_SCALE_INIT = 1\n",
        "        # regularization\n",
        "        self.n_head = config.n_head\n",
        "        self.n_embd = config.n_embd\n",
        "        # not really a 'bias', more of a mask, but following the OpenAI/HF naming though\n",
        "        self.register_buffer(\"bias\", torch.tril(torch.ones(config.block_size, config.block_size))\n",
        "                                     .view(1, 1, config.block_size, config.block_size))\n",
        "\n",
        "        #total parameter cal = [n_embed*3*n_embed + n_embed*n_embed(from proj)] in attenstion\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, T, C = x.size() # batch size, sequence length, embedding dimensionality (n_embd)\n",
        "        # calculate query, key, values for all heads in batch and move head forward to be the batch dim\n",
        "        qkv = self.c_attn(x)\n",
        "        q, k, v = qkv.split(self.n_embd, dim=2)\n",
        "        k = k.view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)\n",
        "        q = q.view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)\n",
        "        v = v.view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)\n",
        "\n",
        "        # manual implementation of attention\n",
        "        # this materializes the large (T,T) matrix for all the queries and keys\n",
        "        #att = (q @ k.transpose(-2, -1)) * (1.0 / math.sqrt(k.size(-1)))\n",
        "        #att = att.masked_fill(self.bias[:,:,:T,:T] == 0, float('-inf'))\n",
        "        #att = F.softmax(att, dim=-1)\n",
        "        #y = att @ v # (B, nh, T, T) x (B, nh, T, hs) -> (B, nh, T, hs)\n",
        "\n",
        "        #this is calling flash attention as torch compile directly cannot see the upper thing as one operation\n",
        "        y = F.scaled_dot_product_attention(q, k, v, is_causal=True)\n",
        "\n",
        "        y = y.transpose(1, 2).contiguous().view(B, T, C) # re-assemble all head outputs side by side\n",
        "        # output projection\n",
        "        y = self.c_proj(y)\n",
        "        return y\n",
        "\n",
        "\n",
        "class MLP(nn.Module): #multilayerperceptron that is feed forward network\n",
        "\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.c_fc    = nn.Linear(config.n_embd, 4 * config.n_embd)\n",
        "        self.gelu    = nn.GELU(approximate='tanh')      #NewGELU()\n",
        "        self.c_proj  = nn.Linear(4 * config.n_embd, config.n_embd)\n",
        "        self.c_proj.NANOGPT_SCALE_INIT = 1\n",
        "\n",
        "        \"\"\"\n",
        "        Here total parameter= n_embed*4*n_embed + 4*n_embed*n_embed\n",
        "        \"\"\"\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.c_fc(x)\n",
        "        x = self.gelu(x)\n",
        "        x = self.c_proj(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class Block(nn.Module):\n",
        "\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.ln_1 = nn.LayerNorm(config.n_embd)\n",
        "        self.attn = CausalSelfAttention(config)\n",
        "        self.ln_2 = nn.LayerNorm(config.n_embd)\n",
        "        self.mlp = MLP(config)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.attn(self.ln_1(x))\n",
        "        x = x + self.mlp(self.ln_2(x))\n",
        "        return x\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class GPTConfig:\n",
        "    block_size: int = 1024\n",
        "    vocab_size: int = 50257\n",
        "    n_layer: int = 12\n",
        "    n_head: int = 12\n",
        "    n_embd: int = 768\n",
        "\n",
        "\"\"\"\n",
        "  For each norm there are two parameter of each n_embed size:\n",
        "  learned parameter and bias parameter there fore for each norm there are 2*n_embed parameter\n",
        "  there are three normalization used here :\n",
        "  3*2*n_embed = 6*n_embed  for layer normalization\n",
        "\n",
        "\n",
        "  Parameter for embedding :\n",
        "  vocab_size*n_embed\n",
        "\n",
        "  there is no parameter for lm_head because it parameter is shared with embedding parameter\n",
        "\n",
        "  for positional embedding parameter:\n",
        "    block_size*n_embed\n",
        "\"\"\"\n",
        "\n",
        "class GPT(nn.Module):\n",
        "\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "\n",
        "        self.transformer = nn.ModuleDict(dict(\n",
        "            wte = nn.Embedding(config.vocab_size, config.n_embd),\n",
        "            wpe = nn.Embedding(config.block_size, config.n_embd),  #block size is token size, n_embed is size of 1 tokens\n",
        "            h = nn.ModuleList([Block(config) for _ in range(config.n_layer)]),\n",
        "            ln_f = nn.LayerNorm(config.n_embd),\n",
        "        ))\n",
        "\n",
        "        self.lm_head = nn.Linear(config.n_embd, config.vocab_size, bias=False)  #this can be change in fine tuning based on the labeled data based on GPT1\n",
        "\n",
        "\n",
        "\n",
        "        #weight sharing (bottom token weight weight same as end weight ) from attention is all you need paper in that paper 30 dedicated to this research\n",
        "        self.transformer.wte.weight = self.lm_head.weight\n",
        "\n",
        "        #init parameters from gpt2 github code\n",
        "\n",
        "        self.apply(self._init_weights)\n",
        "    #this initiallisation is from gpt2 code\n",
        "    def _init_weights(self, module):\n",
        "      if isinstance(module, nn.Linear):\n",
        "        std = 0.02\n",
        "        if hasattr(module, 'NANOGPT_SCALE_INIT'): #we mul the  std by 1/sqr(N) because when standard deviation grows inside the residual and we can to keep it small so that when it grows it become normal value of std =0.02 as here\n",
        "          std *= (2*self.config.n_layer)**-0.5  # 2x 12 layer we use this because std is adding in evdry residual path initially we are diving it with sqrt(2*12) so that after adding it becomes 0.02\n",
        "          #here N is no of residual layer at each layer there are two residual layer that short circuiting of x and there are 12 layers\n",
        "          #If you are really confused about what is residual layer search what is residual connection\n",
        "          \"\"\"\n",
        "            This can be prove with simple basic concept let say X1 and X1 are random variable(rv) with std = 0.02 and var = std**2\n",
        "            When they are sum ,variance are also added assumption each rv is independent\n",
        "            Var(x) = Var(X1)+Var(X2) = 0.02**2 + 0.002**2 = 2*0.002^2  std  = sqrt(2)*0.02   that std is increase by factor sqrt(2) because only two random variable are there\n",
        "            If we want to scale it down we have to divide it by sqrt(2)\n",
        "            We want the final weight of residual connection should have std=0.02\n",
        "          \"\"\"\n",
        "        torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
        "        if module.bias is not None:\n",
        "          torch.nn.init.zeros_(module.bias)\n",
        "      elif isinstance(module, nn.Embedding):\n",
        "        torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
        "\n",
        "    def forward(self, idx, targets=None):\n",
        "      B, T = idx.size()\n",
        "      assert T <= self.config.block_size, f\"Cannot forward of sequence of length {T}, block size is only {self.config.block_size}\"\n",
        "\n",
        "      pos = torch.arange(0,T, dtype=torch.long, device=idx.device)\n",
        "      pos_emb = self.transformer.wpe(pos)\n",
        "      tok_emb = self.transformer.wte(idx)\n",
        "      x = tok_emb + pos_emb\n",
        "      for block in self.transformer.h:\n",
        "        x = block(x)\n",
        "      x = self.transformer.ln_f(x)\n",
        "      logits = self.lm_head(x)\n",
        "      loss = None\n",
        "      if targets is not None:\n",
        "        loss = F.cross_entropy(logits.view(-1, logits.size(-1)), targets.view(-1))\n",
        "      return logits, loss\n",
        "\n",
        "    @classmethod\n",
        "    def from_pretrained(cls, model_type):\n",
        "        \"\"\"Loads pretrained GPT-2 model weights from huggingface\"\"\"\n",
        "        assert model_type in {'gpt2', 'gpt2-medium', 'gpt2-large', 'gpt2-xl'}\n",
        "        from transformers import GPT2LMHeadModel\n",
        "        print(\"loading weights from pretrained gpt: %s\" % model_type)\n",
        "\n",
        "        # n_layer, n_head and n_embd are determined from model_type\n",
        "        config_args = {\n",
        "            'gpt2':         dict(n_layer=12, n_head=12, n_embd=768),  # 124M params\n",
        "            'gpt2-medium':  dict(n_layer=24, n_head=16, n_embd=1024), # 350M params\n",
        "            'gpt2-large':   dict(n_layer=36, n_head=20, n_embd=1280), # 774M params\n",
        "            'gpt2-xl':      dict(n_layer=48, n_head=25, n_embd=1600), # 1558M params\n",
        "        }[model_type]\n",
        "        config_args['vocab_size'] = 50257 # always 50257 for GPT model checkpoints\n",
        "        config_args['block_size'] = 1024 # always 1024 for GPT model checkpoints\n",
        "        # create a from-scratch initialized minGPT model\n",
        "        config = GPTConfig(**config_args)\n",
        "        model = GPT(config)\n",
        "        sd = model.state_dict()\n",
        "        sd_keys = sd.keys()\n",
        "        sd_keys = [k for k in sd_keys if not k.endswith('.attn.bias')] # discard this mask / buffer, not a param\n",
        "\n",
        "        # init a huggingface/transformers model\n",
        "        model_hf = GPT2LMHeadModel.from_pretrained(model_type)\n",
        "        sd_hf = model_hf.state_dict()\n",
        "\n",
        "        # copy while ensuring all of the parameters are aligned and match in names and shapes\n",
        "        sd_keys_hf = sd_hf.keys()\n",
        "        sd_keys_hf = [k for k in sd_keys_hf if not k.endswith('.attn.masked_bias')] # ignore these, just a buffer\n",
        "        sd_keys_hf = [k for k in sd_keys_hf if not k.endswith('.attn.bias')] # same, just the mask (buffer)\n",
        "        transposed = ['attn.c_attn.weight', 'attn.c_proj.weight', 'mlp.c_fc.weight', 'mlp.c_proj.weight']\n",
        "        # basically the openai checkpoints use a \"Conv1D\" module, but we only want to use a vanilla Linear\n",
        "        # this means that we have to transpose these weights when we import them\n",
        "        assert len(sd_keys_hf) == len(sd_keys), f\"mismatched keys: {len(sd_keys_hf)} != {len(sd_keys)}\"\n",
        "        for k in sd_keys_hf:\n",
        "            if any(k.endswith(w) for w in transposed):\n",
        "                # special treatment for the Conv1D weights we need to transpose\n",
        "                assert sd_hf[k].shape[::-1] == sd[k].shape\n",
        "                with torch.no_grad():\n",
        "                    sd[k].copy_(sd_hf[k].t())\n",
        "            else:\n",
        "                # vanilla copy over the other parameters\n",
        "                assert sd_hf[k].shape == sd[k].shape\n",
        "                with torch.no_grad():\n",
        "                    sd[k].copy_(sd_hf[k])\n",
        "\n",
        "        return model\n",
        "\n",
        "    def configure_optimizers(self, weight_decay, learning_rate, device):\n",
        "      #start with all of the canditae parameters that requires grad\n",
        "      param_dict = {pn: p for pn, p in self.named_parameters()}\n",
        "      param_dict = {pn:p for pn,p in param_dict.items() if p.requires_grad}\n",
        "      #create optim groups Any parameters that is 2D will be weught decayed otherwise no\n",
        "      #i.e. all weight tensor in matmuls + embedding decay, all biases and layernorms don't\n",
        "      decay_params = [p for n, p  in param_dict.items() if p.dim() >= 2]\n",
        "      nodecay_params = [p for n,p  in param_dict.items() if p.dim() < 2]\n",
        "      optim_groups = [\n",
        "          {'params':decay_params, 'weight_decay': weight_decay},\n",
        "          {'params': nodecay_params, 'weight_decay':0.0}\n",
        "      ]\n",
        "      num_decay_params = sum(p.numel() for p in decay_params)\n",
        "      num_nodecay_params = sum(p.numel() for p in nodecay_params)\n",
        "      print(f\"num decayed parameter tensor: {len(decay_params)}, with {num_decay_params:,} parameter\")\n",
        "      print(f\"nu,m non-deacyed parameter tenor: {len(nodecay_params)}, with {num_nodecay_params:,} parameter\")\n",
        "      # create adam optimiser and use the fused version if it is available\n",
        "      fused_available = 'fused' in inspect.signature(torch.optim.AdamW).parameters  #to see whether fused option is present or not in pytorch\n",
        "      print(f\"fused_available: {fused_available} and device is cuda: { device == 'cuda'} \")\n",
        "      use_fused = fused_available and  device == 'cuda' #if gpu then use cuda\n",
        "      print(f\"using fused AdamW: {use_fused}\")\n",
        "      optimizer = torch.optim.AdamW(optim_groups, lr=learning_rate, betas=(0.9, 0.95), eps=1e-8, fused=use_fused)\n",
        "      return optimizer\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "7FEwqI2mNu6E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kWGuphIOjXzf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dO_Q_2zP-t4F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "8zxqAE_OOVr8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6cdbcf4f-b8f9-4c66-8528-a205df74b7b5",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-11-03 06:56:08--  https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1115394 (1.1M) [text/plain]\n",
            "Saving to: ‘input.txt’\n",
            "\n",
            "input.txt           100%[===================>]   1.06M  --.-KB/s    in 0.01s   \n",
            "\n",
            "2024-11-03 06:56:09 (87.3 MB/s) - ‘input.txt’ saved [1115394/1115394]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tiktoken datasets tqdm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "ZxegFkfPUjMz",
        "outputId": "5f3945bd-2d3d-4e89-d674-bdfd7d799cdc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Collecting datasets\n",
            "  Downloading datasets-3.1.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.6)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2024.9.11)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.32.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.10)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.24.7)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.17.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets) (0.2.0)\n",
            "Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading datasets-3.1.0-py3-none-any.whl (480 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m36.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, fsspec, dill, tiktoken, multiprocess, datasets\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.10.0\n",
            "    Uninstalling fsspec-2024.10.0:\n",
            "      Successfully uninstalled fsspec-2024.10.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.1.0 dill-0.3.8 fsspec-2024.9.0 multiprocess-0.70.16 tiktoken-0.8.0 xxhash-3.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import multiprocessing as mp\n",
        "import numpy as np\n",
        "import tiktoken\n",
        "from datasets import load_dataset\n",
        "from tqdm import tqdm\n",
        "\n",
        "local_dir = \"filter_fineweb5B\"\n",
        "shard_size = int(1e8)\n",
        "\n",
        "\n",
        "DATA_CACHE_DIR = os.path.join(os.getcwd(), local_dir)\n",
        "os.makedirs(DATA_CACHE_DIR , exist_ok=True)\n",
        "\n",
        "#download the dataset\n",
        "\n",
        "#fw = load_dataset(\"HuggingFaceFW/fineweb-edu\", name=remote_name, split=\"train\")\n",
        "# Define the specific parquet files you want to load (first seven)\n",
        "data_files = [f\"sample/10BT/{i:03d}_00000.parquet\" for i in range(2)]\n",
        "\n",
        "# Load only these specific files from the dataset\n",
        "fw = load_dataset(\n",
        "    \"HuggingFaceFW/fineweb-edu\",\n",
        "    data_files=data_files,\n",
        "    split=\"train\"\n",
        ")"
      ],
      "metadata": {
        "id": "Ad4f8XBkSVMo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269,
          "referenced_widgets": [
            "72eb92756883492fbff632db7a37ffe3",
            "d127416c462f47c6bbea1478cfb8244c",
            "654a9d6f21824c7b88492f74fc224343",
            "43dde6a2500a4dd38cc6f20949a6b653",
            "bc9e3b5e7a3b4ee58c33982e27b02b75",
            "90354aa6ae7845fcb38dce3fb2396dfa",
            "d6f6c94a4d8d4f9d83da0b96e49872c4",
            "04ab619ea18a40d1bf4d4cb3f772704f",
            "f8fce0a0524a43e1ae2625a337243c23",
            "bfcea379963e423f9a3c3541d4c3fda3",
            "5534c414ff654e99b029ee16a85da514",
            "60846c71809c48afaa340e4dc6d11c16",
            "e21e2e352bb24139a5b87e5509e4ca47",
            "a6682e6a924a41dbbc89c1b2f90d908f",
            "802ab76421934bb99e37e94d02f983d7",
            "616320ea109f4e8093cc7a5452996b35",
            "39d274d2e0694c2483845a47a885ea56",
            "0a1e62eed56649a7a718b628d0b96551",
            "875ad1b94dbb4a538efa376b3186c8a3",
            "2cdbb8d78f4b4662802705cb7fb5965f",
            "4c7f8fedab38463c8695ca2d082ae46f",
            "8a6201f9eb514534bd168464f3b5d361",
            "4832b38e6b44477eb063c05993741ff3",
            "ad9893768199402ba0db13f3129d3519",
            "ee9e2eac426c4fb387cf4e0c320cc7df",
            "bd1a06d70b6444f78bcf0c56fe8c8ba0",
            "4768666c04b64585b5bac800e538710e",
            "6d420534d491446b98eccc9a107389aa",
            "bd61488123a246d2ac8da5e8aa169108",
            "c4571d99446b41e6859af1b9f0440d01",
            "3de38dceb3a34a59923c9b73223a14fd",
            "1f6c449dff414eca83d9229652202fdc",
            "f078c886373a4f2c9b30473a23b862ad",
            "8c6afa49f98340c893bd2a3f41420a0e",
            "ed357ee222774f778bca0e3f9600693d",
            "6591a004e16a4151a892a511ef2927cd",
            "641c75c3ab6a4afbb4d71a5c8bf9cc94",
            "8cc6ae667445469ba86db8d2d2d9c61f",
            "46bdefba2ea24daabcf48b8762393fb9",
            "4de0e0982d874540b2bada5aa570b0ef",
            "62431d1974ef4eb8b5f67006de3d9a4e",
            "e773e6f080924ac58f8f0672dfed145a",
            "f40212cc39e94be08cfc375204e8334e",
            "cfbfcd3861ce43cfa98957d1188b7a25"
          ]
        },
        "outputId": "49fcf301-6eb8-47fc-9302-3cd10861d38a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/23.3k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "72eb92756883492fbff632db7a37ffe3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "000_00000.parquet:   0%|          | 0.00/2.15G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "60846c71809c48afaa340e4dc6d11c16"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "001_00000.parquet:   0%|          | 0.00/2.15G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4832b38e6b44477eb063c05993741ff3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8c6afa49f98340c893bd2a3f41420a0e"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf /content/filter_fineweb5B"
      ],
      "metadata": {
        "id": "9arB4GGd-gx7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize(doc):\n",
        "  enc = tiktoken.get_encoding(\"gpt2\")\n",
        "  eot = enc._special_tokens[\"<|endoftext|>\"]\n",
        "  tokens = [eot]\n",
        "  tokens += enc.encode(doc[\"text\"], allowed_special={\"<|endoftext|>\"})\n",
        "  tokens_np = np.array(tokens, dtype=np.uint16)\n",
        "  assert (0 <= tokens_np).all() and (tokens_np < 2**16).all(), \"greater than 2**16 ie that is file is too big\"\n",
        "  return tokens_np\n",
        "\n",
        "def write_datafile_in_byte(file_name, tokens_np):\n",
        "  np.save(file_name, tokens_np)\n",
        "  # with open(file_name, \"wb\") as file:\n",
        "  #   file.write(tokens_np.tobytes())  in these way we are saving the file as .bin format that is byte not npy\n"
      ],
      "metadata": {
        "id": "IMnvMKmeSYTR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nprocessors = max(1, int(os.cpu_count()/2) )\n",
        "print(f\"using {nprocessors} processes\")"
      ],
      "metadata": {
        "id": "kn_tO5AoVRNR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c4294c1-977e-4139-883d-3f13170e5788"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "using 4 processes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#there are some changes here handing some new cases other than the karpathy code"
      ],
      "metadata": {
        "id": "SI5yU3BXowcf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with mp.Pool(nprocessors) as pool:\n",
        "  shard_index = 0\n",
        "  all_tokens_np = np.empty((shard_size,), dtype=np.uint16)\n",
        "  token_count = 0\n",
        "  progress_bar = None\n",
        "  for tokens in pool.imap(tokenize, fw, chunksize=8):\n",
        "    if token_count + len(tokens) < shard_size:\n",
        "      all_tokens_np[token_count:token_count+len(tokens)] = tokens\n",
        "      token_count += len(tokens)\n",
        "      if not progress_bar:\n",
        "        progress_bar = tqdm(total=shard_size, unit=\"token\", desc=f\"writing shard {shard_index}\")\n",
        "      progress_bar.update(len(tokens))\n",
        "    else:\n",
        "      split = \"val\" if shard_index == 0 else \"train\"\n",
        "      file_name = os.path.join(DATA_CACHE_DIR, f\"partialfineweb_{split}_{shard_index:04d}.npy\")\n",
        "      remaining_token = shard_size - token_count\n",
        "      progress_bar.update(remaining_token)\n",
        "      all_tokens_np[token_count:token_count+remaining_token] = tokens[:remaining_token]\n",
        "      write_datafile_in_byte(file_name, all_tokens_np)\n",
        "      shard_index += 1\n",
        "      progress_bar.close()\n",
        "      progress_bar = None\n",
        "\n",
        "      remaining_tokens = tokens[remaining_token:]\n",
        "\n",
        "      while len(remaining_tokens) > shard_size:\n",
        "          split = \"val\" if shard_index == 0 else \"train\"\n",
        "          file_name = os.path.join(DATA_CACHE_DIR, f\"partialfineweb{split}_{shard_index:04d}.npy\")\n",
        "          progress_bar = tqdm(total=shard_size, unit=\"token\", desc=f\"writing shard {shard_index}\")\n",
        "          all_tokens_np[0:shard_size] = remaining_tokens[:shard_size]\n",
        "          write_datafile_in_byte(file_name, all_tokens_np)\n",
        "          progress_bar.update(shard_size)\n",
        "          progress_bar.close()\n",
        "          shard_index += 1\n",
        "          remaining_tokens = remaining_tokens[shard_size:]\n",
        "\n",
        "      all_tokens_np[0:len(remaining_tokens)] = remaining_tokens\n",
        "      token_count = len(remaining_tokens)\n",
        "\n",
        "\n",
        "  if token_count > 0:\n",
        "    split = \"val\" if shard_index == 0 else \"train\"\n",
        "    file_name = os.path.join(DATA_CACHE_DIR, f\"partialfineweb{split}_{shard_index:04d}.npy\")\n",
        "    write_datafile_in_byte(file_name, all_tokens_np)\n",
        "    if progress_bar:\n",
        "      progress_bar.close()\n"
      ],
      "metadata": {
        "id": "7rSvEh8UVhHk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "3779f5e0-3685-43cf-f24b-2f0d5df390d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "writing shard 0: 100%|██████████| 100000000/100000000 [00:19<00:00, 5031439.48token/s]\n",
            "writing shard 1: 100%|█████████▉| 99997871/100000000 [00:19<00:00, 5004187.96token/s]\n",
            "writing shard 2: 100%|█████████▉| 99999982/100000000 [00:19<00:00, 5047613.45token/s]\n",
            "writing shard 3: 100%|█████████▉| 99999934/100000000 [00:20<00:00, 4998802.15token/s]\n",
            "writing shard 4: 100%|█████████▉| 99999796/100000000 [00:19<00:00, 5088597.84token/s]\n",
            "writing shard 5: 100%|█████████▉| 99998855/100000000 [00:20<00:00, 4991094.26token/s]\n",
            "writing shard 6: 100%|█████████▉| 99997594/100000000 [00:19<00:00, 5005227.41token/s]\n",
            "writing shard 7: 100%|█████████▉| 99996910/100000000 [00:19<00:00, 5020091.50token/s]\n",
            "writing shard 8: 100%|█████████▉| 99999293/100000000 [00:19<00:00, 5053836.77token/s]\n",
            "writing shard 9: 100%|█████████▉| 99997859/100000000 [00:19<00:00, 5032682.81token/s]\n",
            "writing shard 10: 100%|█████████▉| 99999807/100000000 [00:20<00:00, 4974472.47token/s]\n",
            "writing shard 11: 100%|█████████▉| 99999526/100000000 [00:20<00:00, 4986128.43token/s]\n",
            "writing shard 12: 100%|█████████▉| 99996988/100000000 [00:20<00:00, 4986330.16token/s]\n",
            "writing shard 13: 100%|█████████▉| 99995680/100000000 [00:20<00:00, 4941010.44token/s]\n",
            "writing shard 14: 100%|█████████▉| 99992326/100000000 [00:20<00:00, 4842211.44token/s]\n",
            "writing shard 15:   3%|▎         | 3314602/100000000 [00:00<00:17, 5390520.34token/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install -y p7zip-full"
      ],
      "metadata": {
        "id": "TlEFj2tOEmYh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "!7z x compressed_file.7z  #for uncompressing\n",
        "```"
      ],
      "metadata": {
        "id": "Z00cENN4F3H-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!7z a -t7z -mx=8 /content/filter_fineweb5B.7z /content/filter_fineweb5B"
      ],
      "metadata": {
        "id": "_q3ZWmH6Er_u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('/content/filter_fineweb5B.7z')"
      ],
      "metadata": {
        "id": "TBk_7rUeNwZu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r /content/filter_fineweb5B.zip /content/filter_fineweb5B\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "RbBSwOjSgMsI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_return_sequences = 5\n",
        "max_length = 30\n"
      ],
      "metadata": {
        "id": "mBJCGe7wObXW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tiktoken\n"
      ],
      "metadata": {
        "id": "w89qkiO-Oh8p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "812db883-1118-477b-b457-7676d41aff7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (0.8.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2024.9.11)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2024.8.30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "Here's a breakdown of the issue:\n",
        "\n",
        "You are using torch.compile to optimize your model, and PyTorch Inductor is selected as the backend.\n",
        "Inductor requires the Triton library to generate efficient kernels for your model's operations.\n",
        "However, either Triton is not installed in your environment or the installed version is not compatible with Inductor.\n",
        "```"
      ],
      "metadata": {
        "id": "2xmEgCWp9VTN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install triton  #this is used for torch.compile\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FWlW_5dY9E6e",
        "outputId": "641bc353-4fc6-4588-91f0-7bb53800d00e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting triton\n",
            "  Downloading triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton) (3.16.1)\n",
            "Downloading triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.5/209.5 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: triton\n",
            "Successfully installed triton-3.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken\n",
        "import time\n",
        "import triton\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "YMEwimAoOlA3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_tokens(file_name):\n",
        "        npt = np.load(file_name)\n",
        "        return torch.tensor(npt, dtype=torch.long)"
      ],
      "metadata": {
        "id": "9l0Dn7GRuR9d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken\n",
        "\n",
        "class DataLoaderLite:\n",
        "  def __init__(self, B, T, process_rank, num_processes, split):\n",
        "    self.B = B\n",
        "    self.T = T\n",
        "    self.process_rank = process_rank\n",
        "    self.num_processes = num_processes\n",
        "    assert split in {'train', 'val'}\n",
        "\n",
        "    #getting the shard filenames\n",
        "    data_root = \"filter_fineweb5B\"\n",
        "    shards = os.listdir(data_root)\n",
        "    shards = [s for s in shards if split in s]\n",
        "    shards = sorted(shards)\n",
        "    shards = [os.path.join(data_root, s) for s in shards]\n",
        "    self.shards = shards\n",
        "    assert len(shards) > 0, f\"no shards found for {split} split\"\n",
        "    if master_process:\n",
        "      print(f\"found {len(shards)} shards for split {split}\")\n",
        "\n",
        "    self.reset()\n",
        "\n",
        "  def reset(self):\n",
        "      self.current_shard = 0\n",
        "      self.tokens = load_tokens(self.shards[self.current_shard])\n",
        "      self.current_position = self.B*self.T*self.process_rank\n",
        "\n",
        "\n",
        "    # with open('input.txt','r') as f:\n",
        "    #   text = f.read()\n",
        "    # enc = tiktoken.get_encoding('gpt2')\n",
        "    # tokens = enc.encode(text)\n",
        "    # self.tokens = torch.tensor(tokens)\n",
        "    # print(f\"loaded {len(self.tokens)} tokens\")\n",
        "    # print(f\"1 epoch = {len(self.tokens) // (B*T*self.num_processes)} batches\")\n",
        "\n",
        "    # self.current_shard = 0\n",
        "    # self.tokens = load_tokens(self.shards[self.current_shard])\n",
        "    # self.current_position = self.B*self.T*self.process_rank  #for eg process rank one with start at 0 as rank == 0 number of rank means number of gpu used together\n",
        "\n",
        "  def next_batch(self):\n",
        "    B, T = self.B, self.T\n",
        "    buf = self.tokens[self.current_position: self.current_position+ B*T + 1]\n",
        "    x = (buf[:-1]).view(B, T)\n",
        "    y = (buf[1:]).view(B, T)\n",
        "    self.current_position += B*T*self.num_processes\n",
        "    if self.current_position + (B*T*self.num_processes + 1) > len(self.tokens):\n",
        "      self.current_shard = (self.current_shard + 1) % len(self.shards)\n",
        "      self.tokens = load_tokens(self.shards[self.current_shard])\n",
        "      self.current_position = B*T*self.process_rank\n",
        "    return x, y"
      ],
      "metadata": {
        "id": "gFW7xXCcOnRU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_batch_size = 524288  #2**19, ~0.5M taken from gpt3 paper\n",
        "B=16\n",
        "T = 1024\n",
        "assert total_batch_size%(B*T*ddp_world_size) == 0, \"make sure total_batch size divides B*T\"\n",
        "grad_accum_steps = total_batch_size // (B*T*ddp_world_size)  #ddp_world_size tell what is the total  number of gpu avaiable we have one one now hahaha\n",
        "#if below logic is not provided for each gpu it will print each time master process is the main gpu we assign\n",
        "if master_process:\n",
        "  print(f\"total desired batch size: {total_batch_size}\")\n",
        "  print(f\"=> calculated gradient accumulation steps: {grad_accum_steps}\")"
      ],
      "metadata": {
        "id": "TnR1x7FTOsNW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb34836c-37b7-41a5-d5dd-0fb9a2155e47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total desired batch size: 524288\n",
            "=> calculated gradient accumulation steps: 32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check one file's format\n",
        "file_path = 'filter_fineweb5B/partialfineweb_train_0001.npy'\n",
        "\n",
        "# Print first few bytes\n",
        "with open(file_path, 'rb') as f:\n",
        "    print(\"First few bytes:\", [hex(b) for b in f.read(8)])\n",
        "\n",
        "# Print file size\n",
        "print(\"File size:\", os.path.getsize(file_path))\n",
        "\n",
        "# Try direct numpy load\n",
        "try:\n",
        "    data = np.load(file_path, allow_pickle=True)\n",
        "    print(\"Successfully loaded with shape:\", data.shape)\n",
        "    print(\"Data type:\", data.dtype)\n",
        "except Exception as e:\n",
        "    print(\"Load error:\", str(e))"
      ],
      "metadata": {
        "id": "qQ2yuro14pVq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#hellaswag file download\n",
        "import os\n",
        "import json\n",
        "import requests\n",
        "import tiktoken\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "from transformers import GPT2LMHeadModel\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "#os.getcwd() to get the current working dir\n",
        "DATA_CACHE_DIR = os.path.join(os.getcwd(), \"hellaswag\")\n",
        "\n",
        "def download_file(url: str, fname: str, chunk_size=1024):\n",
        "    \"\"\"Helper function to download a file from a given url\"\"\"\n",
        "    resp = requests.get(url, stream=True)\n",
        "    total = int(resp.headers.get(\"content-length\", 0))\n",
        "    with open(fname, \"wb\") as file, tqdm(\n",
        "        desc=fname,\n",
        "        total=total,\n",
        "        unit=\"iB\",\n",
        "        unit_scale=True,\n",
        "        unit_divisor=1024,\n",
        "    ) as bar:\n",
        "        for data in resp.iter_content(chunk_size=chunk_size):\n",
        "            size = file.write(data)\n",
        "            bar.update(size)\n",
        "\n",
        "hellaswags = {\n",
        "    \"train\": \"https://raw.githubusercontent.com/rowanz/hellaswag/master/data/hellaswag_train.jsonl\",\n",
        "    \"val\": \"https://raw.githubusercontent.com/rowanz/hellaswag/master/data/hellaswag_val.jsonl\",\n",
        "    \"test\": \"https://raw.githubusercontent.com/rowanz/hellaswag/master/data/hellaswag_test.jsonl\",\n",
        "}\n",
        "\n",
        "enc = tiktoken.get_encoding(\"gpt2\")\n",
        "def download(split):\n",
        "    \"\"\"Downloads HellaSwag DATA_CACHE_DIR\"\"\"\n",
        "    os.makedirs(DATA_CACHE_DIR, exist_ok=True)\n",
        "    data_url = hellaswags[split]\n",
        "    data_filename = os.path.join(DATA_CACHE_DIR, f\"hellaswag_{split}.jsonl\")\n",
        "    if not os.path.exists(data_filename):\n",
        "        print(f\"Downloading {data_url} to {data_filename}...\")\n",
        "        download_file(data_url, data_filename)\n",
        "\n"
      ],
      "metadata": {
        "id": "aGIYMOgREmUq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def render_example(example):\n",
        "    \"\"\"\n",
        "    Given the example as a dictionary, render it as three torch tensors:\n",
        "    - tokens (the tokens of context + completion, of size 4xN, as there are always 4 candidates)\n",
        "    - mask (is 1 in the region of the candidate completion, where we evaluate likelihoods)\n",
        "    - label (the index of the correct completion, which we hope has the highest likelihood)\n",
        "    \"\"\"\n",
        "    ctx = example[\"ctx\"]\n",
        "    label = example[\"label\"]\n",
        "    endings = example[\"endings\"]\n",
        "\n",
        "    # data needed to reproduce this eval on the C size\n",
        "    data = {\n",
        "        \"label\": label,\n",
        "        \"ctx_tokens\": None,\n",
        "        \"ending_tokens\": [],\n",
        "    }\n",
        "\n",
        "    # gather up all the tokens\n",
        "    ctx_tokens = enc.encode(ctx)\n",
        "    data[\"ctx_tokens\"] = ctx_tokens\n",
        "    tok_rows = []\n",
        "    mask_rows = []\n",
        "    for end in endings:\n",
        "        end_tokens = enc.encode(\" \" + end) # note: prepending \" \" because GPT-2 tokenizer\n",
        "        tok_rows.append(ctx_tokens + end_tokens)\n",
        "        mask_rows.append([0]*len(ctx_tokens) + [1]*len(end_tokens))\n",
        "        data[\"ending_tokens\"].append(end_tokens)\n",
        "\n",
        "    # have to be careful during the collation because the number of tokens in each row can differ\n",
        "    max_len = max(len(row) for row in tok_rows)\n",
        "    tokens = torch.zeros((4, max_len), dtype=torch.long)\n",
        "    mask = torch.zeros((4, max_len), dtype=torch.long)\n",
        "    #this line of code : let's say 10 is max length and if one token length is 8 then it will add two zeros to compensate with the length it has done both for token and mask_row\n",
        "    for i, (tok_row, mask_row) in enumerate(zip(tok_rows, mask_rows)):\n",
        "        tokens[i, :len(tok_row)] = torch.tensor(tok_row)\n",
        "        mask[i, :len(mask_row)] = torch.tensor(mask_row)\n",
        "\n",
        "    return data, tokens, mask, label\n",
        "    \"\"\"\n",
        "      tokens are the example [ctx + e1, ctx +e2, ctx+e3, ctx+e4] that means there are four option\n",
        "      mask tells which one are options by labelling each option with 1 and ctx as 0\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "def iterate_examples(split):\n",
        "    # there are 10,042 examples in total in val\n",
        "    download(split)\n",
        "    with open(os.path.join(DATA_CACHE_DIR, f\"hellaswag_{split}.jsonl\"), \"r\") as f:\n",
        "        for line in f:\n",
        "            example = json.loads(line)\n",
        "            yield example\n",
        "\n",
        "def get_most_likely_row(tokens, mask, logits):\n",
        "\n",
        "    B, T = tokens.size()\n",
        "    # shift the tokens and mask to the left by one position\n",
        "    shift_tokens = tokens[..., 1:].contiguous()  #remove the starting token\n",
        "    shift_mask = mask[..., 1:].contiguous()\n",
        "    # evaluate the autoregressive loss at all positions\n",
        "    shift_logits = (logits[..., :-1, :]).contiguous()\n",
        "    #shift_tokens = (tokens[..., 1:,(error here) :]).contiguous()\n",
        "    flat_shift_logits = shift_logits.view(-1, shift_logits.size(-1)) #1\n",
        "    flat_shift_tokens = shift_tokens.view(-1) #1\n",
        "    shift_losses = F.cross_entropy(flat_shift_logits, flat_shift_tokens, reduction='none')\n",
        "    shift_losses = shift_losses.view(tokens.size(0), -1)\n",
        "    # now get the average loss just for the completion region (where mask == 1), in each row\n",
        "    shift_mask = (mask[..., 1:]).contiguous() # we must shift mask, so we start at the last prompt token\n",
        "    masked_shift_losses = shift_losses * shift_mask #2\n",
        "    # sum and divide by the number of 1s in the mask\n",
        "    sum_loss = masked_shift_losses.sum(dim=1)\n",
        "    avg_loss = sum_loss / shift_mask.sum(dim=1)\n",
        "    # now we have a loss for each of the 4 completions\n",
        "    # the one with the lowest loss should be the most likely\n",
        "    pred_norm = avg_loss.argmin().item()\n",
        "    return pred_norm\n",
        "\n",
        "    \"\"\"\n",
        "     Let me translate this code in my language:\n",
        "      we take logit before last token because there is no word to match for the prediction of the last words in token.\n",
        "      Now in each row in logit contains the next predicted word\n",
        "      And we need to calculate cross_entropy for each token\n",
        "      there for we need second token from tokens list. (This is simple just think)\n",
        "      now we spreading all the token and calculating the cross entropy loss #1(indicated explanation of #1 code)\n",
        "      Now reshape the losses in (tokens.size(0), -1)  so that we can get the losses for each row in the token\n",
        "      We are shifting the mask because 1 in mask include just the ending part of the sentence but we want to add\n",
        "         the last token of the ctx because that token in logit will have the information for the next token\n",
        "      #2 Now when we * losses with mask we will get losses of just the ending not the ctx\n",
        "      Then we are getting the average loss of each token\n",
        "      We will take the id with the less average loss that is the most likely token\n",
        "    \"\"\""
      ],
      "metadata": {
        "id": "GkPSnK9ScmHY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoaderLite(B=B, T=T, process_rank=ddp_rank, num_processes=ddp_world_size, split='train')   #in original gpt it is 16 but I put 8 because of computer efficiency\n",
        "val_loader = DataLoaderLite(B=B, T=T, process_rank=ddp_rank, num_processes=ddp_world_size, split='val')\n",
        "#if you have not gpu or high efficient gpu you can take high batch intead we do gradient accumulation technique to do the same because batch size it directly corelated to\n",
        "#other paramaters\n",
        "torch.set_float32_matmul_precision('high')\n",
        " #by default it at highest using float32 now it will use tensor 32 as it will cut down some precision but not much\n",
        "#it cut cut down just the mantissa {1.23234 * 10^2} 1.23234 is mantissa and base and exponential"
      ],
      "metadata": {
        "id": "QMb44ut4PUWV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7fd01ca4-5441-4b7f-b1dc-fdd39ac0369f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "found 15 shards for split train\n",
            "found 1 shards for split val\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "import code: code.interact(local=locals())\n",
        " ```\n",
        " this is important when we need to stop code in middle and check the variable or anything you want with the above code"
      ],
      "metadata": {
        "id": "2n_bNTKqAbrX"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VkAvNOBW_xRq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_ijjN0aeACXy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "EvHZNo75__ri"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "# import torch_xla\n",
        "# import torch_xla.core.xla_model as xm   for tpu we need this\n",
        "import time\n",
        "import torch.distributed as dist\n",
        "\n",
        "\n",
        "torch.manual_seed(1337)\n",
        "if torch.cuda.is_available():\n",
        "  torch.cuda.manual_seed_all(1337)\n",
        "\n",
        "\n",
        "\n",
        "# I add this to suppress some error I have to look into these afterwards\n",
        "import torch._dynamo\n",
        "torch._dynamo.config.suppress_errors = False\n",
        "torch._dynamo.config.automatic_dynamic_shapes = True\n",
        "\n",
        "# Get TPU device\n",
        "# device = xm.xla_device()  initially I was using free TPU that's why I was using this code\n",
        "\n",
        "# Initialize model and move it to TPU\n",
        "model = GPT(GPTConfig(vocab_size=50304))  # 50304 is nice number many times divisible by two if number is not good then we should at first increase the num not decrease and see nearest number that can be used that is divisible by many time by two\n",
        "#because we know computer understand binary number that why it can really compute first if the number is in 2 to the power even it gpu at first it do all the calculation that has 2 power then after than that it will handle all the other number\n",
        "model = model.to(device)\n",
        "\n",
        "\n",
        "model = torch.compile(\n",
        "    model\n",
        ")\n",
        "if ddp:\n",
        "  model = torch.nn.parallel.DistributedDataParallel(model, device_ids=[ddp_local_rank])\n",
        "\n",
        "raw_model = model.module if ddp else model\n",
        "\n",
        "max_lr = 6e-4\n",
        "min_lr = max_lr*0.1\n",
        "warmup_steps = 286 #as gpt 3 10B parameter they take 3% of token in warmup step our 5B parameter 3% is 150 million 150m /2**19~286\n",
        "max_steps = 9536 #this is just got by we have 5B tokens it each step we process 2**19 tokens total number of step in 1 epoch\n",
        "\n",
        "\n",
        "#learning rate based on step intially it will increase unit the max_learning rate then it will decrease based on cosine\n",
        "def get_lr(it):\n",
        "  if it < warmup_steps:\n",
        "    return max_lr*(it+1)/ warmup_steps\n",
        "  if it > max_steps:\n",
        "    return min_lr\n",
        "  decay_ratio = (it - warmup_steps) / (max_steps - warmup_steps)\n",
        "  assert 0 <= decay_ratio <= 1\n",
        "  coeff = 0.5 * (1.0 + math.cos(math.pi*decay_ratio))\n",
        "  return min_lr + coeff*(max_lr - min_lr)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#optimizer = torch.optim.AdamW(model.parameters(), lr=3e-4, betas=(0.9, 0.95), eps=1e-8)\n",
        "optimizer = raw_model.configure_optimizers(weight_decay=0.1, learning_rate=6e-4, device=device)\n",
        "#optimizer = torch.optim.AdamW(model.parameters(), lr=6e-4, betas=(0.9, 0.95), eps=1e-8, weight_decay=0.1, fused=False) #we are using false it showing some error in tensor only available for cuda\n",
        "\n",
        "#accumulation_steps = 2  # Accumulate gradients over 2 steps\n",
        "\n",
        "#log directory to write helloswag and loss value\n",
        "log_dir = \"log\"\n",
        "os.makedirs(log_dir, exist_ok=True)\n",
        "log_file = os.path.join(log_dir, f\"log.txt\")\n",
        "with open(log_file, \"w\") as f: #open for writing for clearing the file\n",
        "  pass\n",
        "rang = 10000\n",
        "for step in range(rang):\n",
        "    t0 = time.time()\n",
        "    last_step = (step == (rang - 1))\n",
        "\n",
        "    # doing validation after 100 steps\n",
        "    if step % 50 == 0:\n",
        "      model.eval()\n",
        "      val_loader.reset()\n",
        "      with torch.no_grad():\n",
        "        val_loss_accum = 0\n",
        "        val_loss_steps = 20\n",
        "        for _ in range(val_loss_steps):\n",
        "          x, y = val_loader.next_batch()\n",
        "          x, y = x.to(device), y.to(device)\n",
        "          with torch.autocast(device_type=device, dtype=torch.float16): #bfloat16 --> float16 due to gpu compute capacity less than 8\n",
        "            logits, loss = model(x, y)\n",
        "          loss = loss/val_loss_steps\n",
        "          val_loss_accum += loss.detach()\n",
        "      if ddp:\n",
        "        dist.all_reduce(val_loss_accum, op=dist.ReduceOp.AVG)\n",
        "      if master_process:\n",
        "        print(f\"validation loss: {val_loss_accum.item():.4f}\")\n",
        "        #saving the value of validation in log.txt\n",
        "        with open(log_file, \"a\") as f:\n",
        "                f.write(f\"{step} val {val_loss_accum.item():.4f}\\n\")\n",
        "        if step > 0 and (step % 5000 == 0 or last_step):\n",
        "                # this is code for intermediate saving of model\n",
        "                checkpoint_path = os.path.join(log_dir, f\"model_{step:05d}.pt\")\n",
        "                checkpoint = {\n",
        "                    'model': raw_model.state_dict(),\n",
        "                    'config': raw_model.config,\n",
        "                    'step': step,\n",
        "                    'val_loss': val_loss_accum.item()\n",
        "                }\n",
        "                # you might also want to add optimizer.state_dict() and\n",
        "                # rng seeds etc., if you wanted to more exactly resume training\n",
        "                torch.save(checkpoint, checkpoint_path)\n",
        "\n",
        "\n",
        "    #helloswag eval\n",
        "    if (step % 50 == 0 or last_step):\n",
        "      num_correct_norm = 0\n",
        "      num_total = 0\n",
        "      for i, example in enumerate(iterate_examples(\"val\")):\n",
        "        if i% ddp_world_size != ddp_rank:\n",
        "          continue\n",
        "        _, tokens, mask, label = render_example(example)\n",
        "        tokens = tokens.to(device)\n",
        "        mask = mask.to(device)\n",
        "        #get the logits\n",
        "        with torch.no_grad():\n",
        "          with torch.autocast(device_type=device, dtype=torch.float16):\n",
        "            logits, _ = model(tokens)\n",
        "          pred_norm = get_most_likely_row(tokens, mask, logits)\n",
        "        num_total += 1\n",
        "        num_correct_norm += int(pred_norm == label)\n",
        "\n",
        "      if ddp:\n",
        "        num_total = torch.tensor(num_total, dtype=torch.long, device=device)\n",
        "        num_correct_norm = torch.tensor(num_correct_norm, dtype=torch.long, device=device)\n",
        "        dist.all_reduce(num_correct_norm, op=dist.ReduceOp.SUM)\n",
        "        dist.all_reduce(num_total, op=dist.ReduceOp.SUM)\n",
        "        num_total = num_total.item()\n",
        "        num_correct_norm = num_correct_norm.item()\n",
        "      acc_norm = num_correct_norm/num_total\n",
        "      if master_process:\n",
        "        print(f\"helloswag accuracy: {num_correct_norm}/{num_total} {acc_norm:.4f}\")\n",
        "        #saving value of hella in log.txt\n",
        "        with open(log_file, \"a\") as f:\n",
        "                f.write(f\"{step} hella {acc_norm:.4f}\\n\")\n",
        "\n",
        "    #generating text\n",
        "    if step > 0 and step % 5 == 0:\n",
        "      model.eval()\n",
        "      num_return_sequences = 4\n",
        "      max_length = 32\n",
        "      enc = tiktoken.get_encoding(\"gpt2\")\n",
        "      tokens = enc.encode(\"Hello, I'm a language model,\")\n",
        "      tokens = torch.tensor(tokens, dtype=torch.long)\n",
        "      tokens = tokens.unsqueeze(0).repeat(num_return_sequences, 1)  #adding dimension to tokens -->(1,T) and then --> (num_return, T)\n",
        "      tokens = tokens.to(device)\n",
        "      sample_rng = torch.Generator(device=device)\n",
        "      sample_rng.manual_seed(42 + ddp_rank)\n",
        "      while tokens.size(1) < max_length:\n",
        "        with torch.no_grad():\n",
        "          logits, loss = model(tokens)  #(B, T, vocab_size)\n",
        "          #take the logits at the last position\n",
        "          logits = logits[:, -1, :]  #(B, vocab_size)\n",
        "          #get the probabilities\n",
        "          probs = F.softmax(logits, dim=-1)\n",
        "          topk_probs, topk_indices = torch.topk(probs, 50, dim=-1)\n",
        "          ix = torch.multinomial(topk_probs, num_samples=1, replacement=True, generator=sample_rng)\n",
        "          xcol = torch.gather(topk_indices, dim=-1, index=ix)\n",
        "          tokens = torch.cat((tokens, xcol), dim=1)\n",
        "          \"\"\"\n",
        "           We are getting the probs of the next token\n",
        "           then we selecting the top 50 possible probs with their index that reduce the chance of predicting unlikely token\n",
        "           we chose the token , the token with higher prob has high likely to select we get id of that token\n",
        "           .gather function helps to get the original index from vocabulary using ix got from .multinomial function\n",
        "           that id is store in xcol and finally added to tokens\n",
        "          \"\"\"\n",
        "      print(f\"tokens: {tokens}\")\n",
        "      for i in range(num_return_sequences):\n",
        "        tokens_list = tokens.tolist()\n",
        "        tokens_to_decode = tokens_list[i][:max_length]\n",
        "        #tokens = tokens[i, :max_length].tolist()  there is showing some error\n",
        "        decoded = enc.decode(tokens_to_decode)\n",
        "        print(f\"rank {ddp_rank} sample {i}: {decoded}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    loss_accum = 0.0\n",
        "    #grad acumulation step is done here we are just adding the gradient unit it match the token size of gpt3\n",
        "    for micro_step in range(grad_accum_steps):\n",
        "      x, y = train_loader.next_batch()\n",
        "      x, y = x.to(device), y.to(device)\n",
        "      with torch.autocast(device_type=device, dtype=torch.float16): #if tpu then xla instead of device -----my model don't support bfloat as it has compute capacity less than 7.5 that's why change it to float16\n",
        "          logits, loss = model(x, y)  #this is use to convert tensor 32 to bfloat16 but only for logits not other weight varible therefore it is called mixed precision\n",
        "      loss = loss / grad_accum_steps  # Scale loss to account for accumulation  because here we are accumualting the loss , in B*T loss is calculated by sum of all the loss divide by num of loss accumulation done i.e reduction is by mean\n",
        "      loss_accum += loss.detach()  #detaching the tensor so that i can keep track of the value just\n",
        "      if ddp:\n",
        "        model.require_backward_grad_sync = (micro_step == grad_accum_steps - 1)  #we don't want to sync all the time that is wastage of gpu we only sync all the loss at the last time\n",
        "      loss.backward()\n",
        "\n",
        "    if ddp:\n",
        "      dist.all_reduce(loss_accum, op=dist.ReduceOp.AVG)   #this loss accum is available is all the rank and it average all the loss_accum and average it\n",
        "\n",
        "\n",
        "    norm = torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)  # this is actally root mean square of all the gradient if prevents the model to deal with bad batch data that might lead to spike in the grad\n",
        "    lr = get_lr(step)\n",
        "    for param_group in optimizer.param_groups:\n",
        "      param_group['lr'] = lr\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "    torch.cuda.synchronize() #wait for the gpu to finish the work\n",
        "    t1 = time.time()\n",
        "    tokens_processed = train_loader.B*train_loader.T*grad_accum_steps\n",
        "    tokens_per_sec = tokens_processed/(t1-t0)\n",
        "    if master_process:\n",
        "        print(f\"step {step} | loss: {loss_accum.item()} | lr: {lr:.4e} | norm: {norm:.4f} | dt={(t1-t0)*1000:.2f}ms | {tokens_per_sec:.2f} tokens/sec\")\n",
        "        #saving value of loss function\n",
        "        with open(log_file, \"a\") as f:\n",
        "            f.write(f\"{step} train {loss_accum.item():.6f}\\n\")\n",
        "\n",
        "\n",
        "if ddp:\n",
        "  dist.destroy_process_group()  #it will dislink the connected gpu\n",
        "\n"
      ],
      "metadata": {
        "id": "YLPwozIRPgmv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0f3a55b-09cd-4b65-b6fe-4ce666d05527"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "num decayed parameter tensor: 50, with 124,354,560 parameter\n",
            "nu,m non-deacyed parameter tenor: 98, with 121,344 parameter\n",
            "fused_available: True and device is cuda: True \n",
            "using fused AdamW: True\n",
            "validation loss: 10.9850\n",
            "helloswag accuracy: 2460/10042 0.2450\n",
            "step 0 | loss: 10.98499870300293 | lr: 2.0979e-06 | norm: 4.5345 | dt=134237.43ms | 3905.68 tokens/sec\n",
            "step 1 | loss: 10.953947067260742 | lr: 4.1958e-06 | norm: 4.4908 | dt=24869.97ms | 21081.17 tokens/sec\n",
            "step 2 | loss: 10.894068717956543 | lr: 6.2937e-06 | norm: 4.4672 | dt=24737.02ms | 21194.47 tokens/sec\n",
            "step 3 | loss: 10.807744979858398 | lr: 8.3916e-06 | norm: 4.3054 | dt=24687.97ms | 21236.58 tokens/sec\n",
            "step 4 | loss: 10.6933012008667 | lr: 1.0490e-05 | norm: 4.2550 | dt=24651.49ms | 21268.01 tokens/sec\n",
            "tokens: tensor([[15496,    11,   314,  1101,   257,  3303,  2746,    11, 41217, 26646,\n",
            "         31589,   403, 28212,   903, 20420, 28858,  5772, 44846, 11235, 25685,\n",
            "         31589, 47645, 18414, 45640, 18377, 30997, 14385, 33252, 17662, 49878,\n",
            "         29799, 31589],\n",
            "        [15496,    11,   314,  1101,   257,  3303,  2746,    11, 34548, 35542,\n",
            "          5772, 13613, 32079, 43859, 24918, 14563, 23106, 41093, 42076, 13394,\n",
            "         45146, 10745, 32079, 23267, 28212, 20420, 21749, 20397, 20363, 41351,\n",
            "          2140, 23267],\n",
            "        [15496,    11,   314,  1101,   257,  3303,  2746,    11, 32079, 38654,\n",
            "         50150, 50150, 34548, 44914, 35548, 34513,  6565, 41093, 13613, 33252,\n",
            "         44450, 18377, 17873,  5772, 15254, 14563,    11, 10220, 31589,  4712,\n",
            "         41351, 17873],\n",
            "        [15496,    11,   314,  1101,   257,  3303,  2746,    11, 14048, 16051,\n",
            "          1980, 43567, 43567, 26760, 14563, 33252, 48870, 47315, 48870, 18589,\n",
            "         22288, 12339, 17662, 32672, 10998, 42657, 33252, 13394, 10220,  5484,\n",
            "         18414, 39871]], device='cuda:0')\n",
            "rank 0 sample 0: Hello, I'm a language model, Twiceatrianticallyun toughestble contributors cynical param investigatesprotTalkantically grievancecolmuphem sinsricaSorryListener Tigersobos Randallantically\n",
            "rank 0 sample 1: Hello, I'm a language model, senateikini param Student Magnet Berman forged UltraHeight rodents iCloud moistwasherinf Magnetisi toughest contributorspieHillary selfishTeslaashingisi\n",
            "rank 0 sample 2: Hello, I'm a language model, Magnetitates745745 senate TCU buddies Cao empty rodents StudentListener Crafting sins dissent param eliminated Ultra,olsanticallyulaTesla dissent\n",
            "rank 0 sample 3: Hello, I'm a language model, Dim acresirc favoring favoring nowadays UltraListenercancerorrectcancer Roose1996starter Tigersillin Yang GraysonListener moistols upgrcolm anchored\n",
            "step 5 | loss: 10.571612358093262 | lr: 1.2587e-05 | norm: 4.0880 | dt=24866.29ms | 21084.29 tokens/sec\n",
            "step 6 | loss: 10.47268009185791 | lr: 1.4685e-05 | norm: 3.6600 | dt=24715.57ms | 21212.86 tokens/sec\n",
            "step 7 | loss: 10.36017894744873 | lr: 1.6783e-05 | norm: 3.3390 | dt=24766.02ms | 21169.65 tokens/sec\n",
            "step 8 | loss: 10.277386665344238 | lr: 1.8881e-05 | norm: 3.2433 | dt=24628.40ms | 21287.95 tokens/sec\n",
            "step 9 | loss: 10.193601608276367 | lr: 2.0979e-05 | norm: 3.3899 | dt=24378.53ms | 21506.13 tokens/sec\n",
            "tokens: tensor([[15496,    11,   314,  1101,   257,  3303,  2746,    11, 47758,    11,\n",
            "          1980, 14048,    11, 49242, 49325,   257, 40705, 49242, 34160, 37579,\n",
            "           286, 32672, 27957, 49325,   262,   290, 33131, 49539,    13,  7527,\n",
            "           262, 49325],\n",
            "        [15496,    11,   314,  1101,   257,  3303,  2746,    11, 38136, 20318,\n",
            "         14048,   262,   286, 20420, 37579, 30193, 18377,    13,  3832, 30467,\n",
            "            11, 28904, 16051,   290,    11,    13,  2398,    11, 37579,   286,\n",
            "         25034, 23724],\n",
            "        [15496,    11,   314,  1101,   257,  3303,  2746,    11,   262,   262,\n",
            "           257, 24344,  1980, 29799, 44642, 28460,   262, 24344, 27957,   262,\n",
            "          2398,   290,   290,   262,   726,  1980, 35433,   262, 37865,   262,\n",
            "            11, 32331],\n",
            "        [15496,    11,   314,  1101,   257,  3303,  2746,    11,  1980,   257,\n",
            "          3077,    13,    11,    13,   262, 49539,    13,  2758, 47645,   262,\n",
            "          3757,  7527,  2398,    13,  7573, 33131, 47531, 34840,  2398,   726,\n",
            "            13, 20498]], device='cuda:0')\n",
            "rank 0 sample 0: Hello, I'm a language model, backdoor,irc Dim,nsicscombe a cryptographicnsicsoooTPPStreamerBot ofillin Shamcombe the and gastro 1886.rich thecombe\n",
            "rank 0 sample 1: Hello, I'm a language model,eworldarel Dim the of contributorsTPPStreamerBot Battlefield sins.awn Sorcerer,rily acres and,.org,TPPStreamerBot of Destruction evacuated\n",
            "rank 0 sample 2: Hello, I'm a language model, the the a telescopeirc Randall yea338 the telescope Sham theorg and and theoyircExplore the semantic the, transporting\n",
            "rank 0 sample 3: Hello, I'm a language model,irc abed.,. the 1886. Apr grievance theiperichorg. profession gastroImprove lumberorgoy. EVER\n",
            "step 10 | loss: 10.130711555480957 | lr: 2.3077e-05 | norm: 3.2155 | dt=24466.56ms | 21428.76 tokens/sec\n",
            "step 11 | loss: 10.08916187286377 | lr: 2.5175e-05 | norm: 3.0704 | dt=24200.06ms | 21664.74 tokens/sec\n",
            "step 12 | loss: 10.034988403320312 | lr: 2.7273e-05 | norm: 3.1691 | dt=24237.46ms | 21631.31 tokens/sec\n",
            "step 13 | loss: 10.012568473815918 | lr: 2.9371e-05 | norm: 3.3463 | dt=24259.30ms | 21611.84 tokens/sec\n",
            "step 14 | loss: 10.00170612335205 | lr: 3.1469e-05 | norm: 3.4758 | dt=24411.98ms | 21476.67 tokens/sec\n",
            "tokens: tensor([[15496,    11,   314,  1101,   257,  3303,  2746,    11, 31009,   262,\n",
            "         40705,   262,    11,   257,   284, 18951, 47315, 10846, 12000, 42496,\n",
            "           286, 32585, 46344,   284,   262,   290, 12000,   329,    13, 40705,\n",
            "           262,   284],\n",
            "        [15496,    11,   314,  1101,   257,  3303,  2746,    11,  7527, 14048,\n",
            "         48962,   262,   286, 14048,   286, 32331,   262,   286, 35662, 32331,\n",
            "            11,  7587, 47645,   290,    11,   286, 14820,    11, 12000,    13,\n",
            "         42496, 28321],\n",
            "        [15496,    11,   314,  1101,   257,  3303,  2746,    11,   262,   262,\n",
            "          3832,   286, 23631, 10897,  3832, 35662,   262,  3832, 23237,   262,\n",
            "         49325,   290,   290,   262, 37579, 31370,    13,   262, 40253,   262,\n",
            "            11, 35433],\n",
            "        [15496,    11,   314,  1101,   257,  3303,  2746,    11, 37579, 14048,\n",
            "          7659,   290,    11,    13,   262, 10897,    13,   726,   262,   262,\n",
            "          1968, 38063, 40705,    13, 20498, 10897,   198, 49894, 49894, 31370,\n",
            "            13, 23300]], device='cuda:0')\n",
            "rank 0 sample 0: Hello, I'm a language model, 191 the cryptographic the, a to introorrect lady seized <+ of FinishSolution to the and seized for. cryptographic the to\n",
            "rank 0 sample 1: Hello, I'm a language model,rich Dim mars the of Dim of transporting the of RH transporting, processing grievance and, of arriving, seized. <+regn\n",
            "rank 0 sample 2: Hello, I'm a language model, the theawn of Certainly Kitawn RH theawn164 thecombe and and theTPPStreamerBotoji. the Cout the,Explore\n",
            "rank 0 sample 3: Hello, I'm a language model,TPPStreamerBot Dim Tit and,. the Kit.oy the theript Nile cryptographic. EVER Kit\n",
            "ikanikanoji. wary\n",
            "step 15 | loss: 10.011675834655762 | lr: 3.3566e-05 | norm: 3.1290 | dt=24875.19ms | 21076.75 tokens/sec\n",
            "step 16 | loss: 9.971290588378906 | lr: 3.5664e-05 | norm: 3.2950 | dt=24705.28ms | 21221.70 tokens/sec\n",
            "step 17 | loss: 9.9862699508667 | lr: 3.7762e-05 | norm: 3.4142 | dt=24632.68ms | 21284.25 tokens/sec\n",
            "step 18 | loss: 9.950332641601562 | lr: 3.9860e-05 | norm: 3.2760 | dt=24507.30ms | 21393.13 tokens/sec\n",
            "step 19 | loss: 9.918389320373535 | lr: 4.1958e-05 | norm: 2.9838 | dt=24480.65ms | 21416.43 tokens/sec\n",
            "tokens: tensor([[15496,    11,   314,  1101,   257,  3303,  2746,    11, 26301,    11,\n",
            "           198,    11,    13,  2398,   257,  2398, 19887, 37579, 40268,  7582,\n",
            "            13, 15420, 50138,   284,    11,   286, 38438,   257,   262,   884,\n",
            "            11,   284],\n",
            "        [15496,    11,   314,  1101,   257,  3303,  2746,    11, 31009, 33821,\n",
            "         27069,    11,   262,    11,   286,  5347,    11,    13, 23237, 37579,\n",
            "            13,   198, 23237,   286,    13,   262, 23606,    13, 37579,   286,\n",
            "         50138,   286],\n",
            "        [15496,    11,   314,  1101,   257,  3303,  2746,    11,    13,    11,\n",
            "         50138, 24746, 24746, 31009, 32021, 50138,    11,  2398,  2651,    11,\n",
            "           884,   290,   286,    11,   884,    13,    13,    11,  2206,    11,\n",
            "            13, 10897],\n",
            "        [15496,    11,   314,  1101,   257,  3303,  2746,    11,   329, 38239,\n",
            "          5693,   286,    11,    11,   262, 40705,   262, 29799,    11,    11,\n",
            "         38438,  2398,   329,    13, 11610,   329, 41348, 31009,   287,   262,\n",
            "            13, 15420]], device='cuda:0')\n",
            "rank 0 sample 0: Hello, I'm a language model, nephew,\n",
            ",.org aorg projectionsTPPStreamerBot voic shell. Clar 9000 to, ofnova a the such, to\n",
            "rank 0 sample 1: Hello, I'm a language model, 191 Aeg drastic, the, of ing,.164TPPStreamerBot.\n",
            "164 of. the symm.TPPStreamerBot of 9000 of\n",
            "rank 0 sample 2: Hello, I'm a language model,., 9000 Rac Rac 191 GOODMAN 9000,org forward, such and of, such.., deter,. Kit\n",
            "rank 0 sample 3: Hello, I'm a language model, forilan Foundation of,, the cryptographic the Randall,,novaorg for.Orig for skiing 191 in the. Clar\n",
            "step 20 | loss: 9.895120620727539 | lr: 4.4056e-05 | norm: 3.2486 | dt=24721.87ms | 21207.46 tokens/sec\n",
            "step 21 | loss: 9.886502265930176 | lr: 4.6154e-05 | norm: 3.5357 | dt=24495.59ms | 21403.37 tokens/sec\n",
            "step 22 | loss: 9.876821517944336 | lr: 4.8252e-05 | norm: 3.4009 | dt=24523.61ms | 21378.91 tokens/sec\n",
            "step 23 | loss: 9.891227722167969 | lr: 5.0350e-05 | norm: 3.1807 | dt=24572.89ms | 21336.03 tokens/sec\n",
            "step 24 | loss: 9.891902923583984 | lr: 5.2448e-05 | norm: 3.5697 | dt=24600.75ms | 21311.87 tokens/sec\n",
            "tokens: tensor([[15496,    11,   314,  1101,   257,  3303,  2746,    11,  6338,    13,\n",
            "          2398, 41348,    11,  2398,   257, 14820,  5642, 15420, 34283, 43352,\n",
            "           290,  8376,  9432,   257,    11,   262,  3731,   329,   286,   284,\n",
            "            13,   198],\n",
            "        [15496,    11,   314,  1101,   257,  3303,  2746,    11, 38239,  8376,\n",
            "         33725,    13,   286, 41348,   290,  4530,    13,   286,  3731, 14578,\n",
            "            11,   257,   318,   262,    11,   286, 31618,    11,  8628,   290,\n",
            "         17378,   262],\n",
            "        [15496,    11,   314,  1101,   257,  3303,  2746,    11,    11,    11,\n",
            "          3731,  9432, 34283,  8628, 17378, 41348,    13, 14820, 34283,    11,\n",
            "           198,   262,   290,    13,   329, 20498,   286,    13,  3011,    13,\n",
            "            11, 34283],\n",
            "        [15496,    11,   314,  1101,   257,  3303,  2746,    11,   257,  8414,\n",
            "         23548,   262,    13,   257,    11,   287,   286, 39343,   198,    13,\n",
            "          9363, 14820,   329,   286, 44642,   198,  8628,  3011,  5347, 28093,\n",
            "           290,   287]], device='cuda:0')\n",
            "rank 0 sample 0: Hello, I'm a language model, automatically.org skiing,org a arriving manner Clar hurdles Hmm andults objective a, the slight for of to.\n",
            "\n",
            "rank 0 sample 1: Hello, I'm a language model,ilanults Saiyan. of skiing and charges. of slightloaded, a is the, of Parkinson,150 and Vel the\n",
            "rank 0 sample 2: Hello, I'm a language model,,, slight objective hurdles150 Vel skiing. arriving hurdles,\n",
            " the and. for EVER of. gets., hurdles\n",
            "rank 0 sample 3: Hello, I'm a language model, a contestzh the. a, in of antics\n",
            ". Store arriving for of yea\n",
            "150 gets ingSoon and in\n",
            "step 25 | loss: 9.869024276733398 | lr: 5.4545e-05 | norm: 3.4104 | dt=24738.94ms | 21192.82 tokens/sec\n",
            "step 26 | loss: 9.811335563659668 | lr: 5.6643e-05 | norm: 3.1780 | dt=24381.05ms | 21503.91 tokens/sec\n",
            "step 27 | loss: 9.782949447631836 | lr: 5.8741e-05 | norm: 3.3693 | dt=24546.67ms | 21358.82 tokens/sec\n",
            "step 28 | loss: 9.768150329589844 | lr: 6.0839e-05 | norm: 3.3687 | dt=24624.52ms | 21291.30 tokens/sec\n",
            "step 29 | loss: 9.749253273010254 | lr: 6.2937e-05 | norm: 3.3226 | dt=24523.56ms | 21378.95 tokens/sec\n",
            "tokens: tensor([[15496,    11,   314,  1101,   257,  3303,  2746,    11,   884,    13,\n",
            "           726,    13,    11, 14820,   198, 14820,   373,   287, 40061,   357,\n",
            "            11,    12,   357,   198,    13,   290,  6842,   284,   262,    11,\n",
            "            11,   198],\n",
            "        [15496,    11,   314,  1101,   257,  3303,  2746,    11, 42703, 42703,\n",
            "           699,    13,   198, 47531,   290,   884,    13,   198, 12407, 36639,\n",
            "            11,   198, 18136,   290,    11,   262,  2398,    11, 20498,   290,\n",
            "         21111,   198],\n",
            "        [15496,    11,   314,  1101,   257,  3303,  2746,    11,    11,    11,\n",
            "            12, 20498, 29875,    12,  5693,  7815,    13, 11610, 36141,    11,\n",
            "           257,   286,   286,    11,   257,    11,   262,    11, 30920,    11,\n",
            "            13, 12407],\n",
            "        [15496,    11,   314,  1101,   257,  3303,  2746,    11,   198, 20498,\n",
            "         14823,   286,    13,   198,    11, 23724,   262, 14578,    13,    13,\n",
            "         32422, 23631,   284,   262,   884,   329, 23631,    11, 23916,   262,\n",
            "           262, 23724]], device='cuda:0')\n",
            "rank 0 sample 0: Hello, I'm a language model, such.oy., arriving\n",
            " arriving was in imperialist (,- (\n",
            ". and bear to the,,\n",
            "\n",
            "rank 0 sample 1: Hello, I'm a language model,ondingondingious.\n",
            "Improve and such.\n",
            " publishingmonary,\n",
            " recreational and, theorg, EVER andCamp\n",
            "\n",
            "rank 0 sample 2: Hello, I'm a language model,,,- EVER Previously- Foundation stone.Orig 520, a of of, a, the, Hed,. publishing\n",
            "rank 0 sample 3: Hello, I'm a language model,\n",
            " EVERropolitan of.\n",
            ", evacuated theloaded.. Galile Certainly to the such for Certainly, cans the the evacuated\n",
            "step 30 | loss: 9.737792015075684 | lr: 6.5035e-05 | norm: 3.5427 | dt=24792.78ms | 21146.81 tokens/sec\n",
            "step 31 | loss: 9.739312171936035 | lr: 6.7133e-05 | norm: 3.4104 | dt=24478.74ms | 21418.09 tokens/sec\n",
            "step 32 | loss: 9.736136436462402 | lr: 6.9231e-05 | norm: 3.3338 | dt=24436.88ms | 21454.78 tokens/sec\n",
            "step 33 | loss: 9.724387168884277 | lr: 7.1329e-05 | norm: 3.4825 | dt=24402.40ms | 21485.10 tokens/sec\n",
            "step 34 | loss: 9.727178573608398 | lr: 7.3427e-05 | norm: 3.4982 | dt=24348.40ms | 21532.75 tokens/sec\n",
            "tokens: tensor([[15496,    11,   314,  1101,   257,  3303,  2746,    11,  4088,    11,\n",
            "          2398,    11,    13,   257,   329,   284,  7565, 21104, 13020,   873,\n",
            "            13, 29799, 20128,   329,    11,   329,  7587,   884,   290,   257,\n",
            "            11,   329],\n",
            "        [15496,    11,   314,  1101,   257,  3303,  2746,    11,   318,   281,\n",
            "         47531,    11,   290,   318,   290, 22291,    11,   290,  7527, 28321,\n",
            "            13,   262, 14716,   286,    13,   290,   281,    13, 29799,   290,\n",
            "         20128,   286],\n",
            "        [15496,    11,   314,  1101,   257,  3303,  2746,    11,    13,    11,\n",
            "         28321, 28321, 11305,  5693,  4088, 27069,    11,   198,  7565,    11,\n",
            "         40705,   286,   286,    11,  2398,    13,    13,    11,  7306,    11,\n",
            "            13,  2651],\n",
            "        [15496,    11,   314,  1101,   257,  3303,  2746,    11,   257, 28321,\n",
            "         22291,   286,    11,   290,    13,   284,   262,   903,    11,    11,\n",
            "         20128,   198,   198,   290,  4809, 40705,   287,  2206,  5693, 20128,\n",
            "           290,  7527]], device='cuda:0')\n",
            "rank 0 sample 0: Hello, I'm a language model, memory,org,. a for to vary beautifully grainics. Randall projection for, for processing such and a, for\n",
            "rank 0 sample 1: Hello, I'm a language model, is anImprove, and is and214, andrichregn. the accidentally of. and an. Randall and projection of\n",
            "rank 0 sample 2: Hello, I'm a language model,.,regnregn streaming Foundation memory drastic,\n",
            " vary, cryptographic of of,org.., ideal,. forward\n",
            "rank 0 sample 3: Hello, I'm a language model, aregn214 of, and. to theble,, projection\n",
            "\n",
            " and Service cryptographic in deter Foundation projection andrich\n",
            "step 35 | loss: 9.695080757141113 | lr: 7.5524e-05 | norm: 3.8838 | dt=24576.14ms | 21333.21 tokens/sec\n",
            "step 36 | loss: 9.704750061035156 | lr: 7.7622e-05 | norm: 3.6956 | dt=24305.39ms | 21570.85 tokens/sec\n",
            "step 37 | loss: 9.698993682861328 | lr: 7.9720e-05 | norm: 3.5376 | dt=24285.79ms | 21588.26 tokens/sec\n",
            "step 38 | loss: 9.655410766601562 | lr: 8.1818e-05 | norm: 3.5623 | dt=24319.54ms | 21558.31 tokens/sec\n",
            "step 39 | loss: 9.611262321472168 | lr: 8.3916e-05 | norm: 3.8605 | dt=24319.24ms | 21558.56 tokens/sec\n",
            "tokens: tensor([[15496,    11,   314,  1101,   257,  3303,  2746,    11,   517,    11,\n",
            "           257,    11,   262,    12,   284,   726, 28321, 14820,   903,  1263,\n",
            "            13,   257, 10846,   284,    11,   286, 26622,   290,    13,   284,\n",
            "            11,   284],\n",
            "        [15496,    11,   314,  1101,   257,  3303,  2746,    11, 14820,  4530,\n",
            "          2282,    11,    13,    11,   290, 10897,    11,   262,  1263, 21111,\n",
            "            13,   290,  2282,   290,    13,   198,  5642,   262,  7565,   286,\n",
            "          3011,   290],\n",
            "        [15496,    11,   314,  1101,   257,  3303,  2746,    11,   262,    11,\n",
            "         10846,  7565, 11841,   726,  4530, 10897,    11,   726, 28321,    11,\n",
            "           329,   290,   286,    11,    11,   262,    13,    11,    11,    11,\n",
            "           262,  3011],\n",
            "        [15496,    11,   314,  1101,   257,  3303,  2746,    11,    13,  2282,\n",
            "           269,   290,    11,    11,   262,    13,   262, 28321,    11,    11,\n",
            "          3011, 40705,   198,   262,  8628,    12,  4507, 34283,  2097,   262,\n",
            "            13, 47531]], device='cuda:0')\n",
            "rank 0 sample 0: Hello, I'm a language model, more, a, the- tooyregn arrivingble big. a lady to, of Applications and. to, to\n",
            "rank 0 sample 1: Hello, I'm a language model, arriving charges saying,., and Kit, the bigCamp. and saying and.\n",
            " manner the vary of gets and\n",
            "rank 0 sample 2: Hello, I'm a language model, the, lady vary dirtyoy charges Kit,oyregn, for and of,, the.,,, the gets\n",
            "rank 0 sample 3: Hello, I'm a language model,. saying c and,, the. theregn,, gets cryptographic\n",
            " the150-Qu hurdles House the.Improve\n",
            "step 40 | loss: 9.59817123413086 | lr: 8.6014e-05 | norm: 3.5788 | dt=24730.42ms | 21200.12 tokens/sec\n",
            "step 41 | loss: 9.58000659942627 | lr: 8.8112e-05 | norm: 3.6740 | dt=24441.58ms | 21450.66 tokens/sec\n",
            "step 42 | loss: 9.580780982971191 | lr: 9.0210e-05 | norm: 4.0560 | dt=24402.86ms | 21484.70 tokens/sec\n",
            "step 43 | loss: 9.5725736618042 | lr: 9.2308e-05 | norm: 4.2571 | dt=24312.90ms | 21564.19 tokens/sec\n",
            "step 44 | loss: 9.55485725402832 | lr: 9.4406e-05 | norm: 5.6862 | dt=24322.17ms | 21555.97 tokens/sec\n",
            "tokens: tensor([[15496,    11,   314,  1101,   257,  3303,  2746,    11, 16030,    11,\n",
            "           287,    11,    13,   726,   329,   284, 14820,  4809, 29875,  4530,\n",
            "            11,  7306,   636,   329,    11,   286,  7582,   286,   262,    13,\n",
            "            13,   286],\n",
            "        [15496,    11,   314,  1101,   257,  3303,  2746,    11,  4809, 10224,\n",
            "         30384,    11,    13,    11,   290, 11038,    11,   262, 14820, 14820,\n",
            "            13,   286,   318,   286,    13,   262,  4809,    13, 15572,   290,\n",
            "          2206,   286],\n",
            "        [15496,    11,   314,  1101,   257,  3303,  2746,    11,    13,    13,\n",
            "         11038,   290,  7582,   884,  2206, 29875,    13,   884, 29875,    13,\n",
            "           726,   286,   286,    13,   726,    11,   262,    13,    13,    13,\n",
            "            11,  6338],\n",
            "        [15496,    11,   314,  1101,   257,  3303,  2746,    11,   262,  1813,\n",
            "          3188,   286,   262,   262,    11,    13,   262,  2580,   262,   262,\n",
            "          1813,   287,   257,   262,   699,   284,   198,    13, 35433,    11,\n",
            "            13, 23916]], device='cuda:0')\n",
            "rank 0 sample 0: Hello, I'm a language model, assembled, in,.oy for to arriving Service Previously charges, ideal part for, of shell of the.. of\n",
            "rank 0 sample 1: Hello, I'm a language model, Service conventional reaff,., and delayed, the arriving arriving. of is of. the Service. illegally and deter of\n",
            "rank 0 sample 2: Hello, I'm a language model,.. delayed and shell such deter Previously. such Previously.oy of of.oy, the..., automatically\n",
            "rank 0 sample 3: Hello, I'm a language model, the given document of the the,. the Che the the given in a theious to\n",
            ".Explore,. cans\n",
            "step 45 | loss: 9.52365493774414 | lr: 9.6503e-05 | norm: 6.3932 | dt=24458.74ms | 21435.61 tokens/sec\n",
            "step 46 | loss: 9.532659530639648 | lr: 9.8601e-05 | norm: 4.5917 | dt=24239.43ms | 21629.55 tokens/sec\n",
            "step 47 | loss: 9.501379013061523 | lr: 1.0070e-04 | norm: 6.3071 | dt=24208.17ms | 21657.49 tokens/sec\n",
            "step 48 | loss: 9.483437538146973 | lr: 1.0280e-04 | norm: 7.4721 | dt=24200.32ms | 21664.51 tokens/sec\n",
            "step 49 | loss: 9.491674423217773 | lr: 1.0490e-04 | norm: 4.8353 | dt=24403.12ms | 21484.47 tokens/sec\n",
            "validation loss: 9.4745\n",
            "helloswag accuracy: 2589/10042 0.2578\n",
            "tokens: tensor([[15496,    11,   314,  1101,   257,  3303,  2746,    11,   317,    11,\n",
            "           257,    11,    13,   884,   329,    12,   442,  1314,    11, 10224,\n",
            "           262,   287, 41348,   329,    11,   286,  1314,   286,   262,   198,\n",
            "            11,   329],\n",
            "        [15496,    11,   314,  1101,   257,  3303,  2746,    11, 21104, 40705,\n",
            "           442,    11,   290,    11,   262,  2581,    11,   290, 17476, 27937,\n",
            "            13,   286,  4203,   286,    13,   290,   318,    13, 40705,   262,\n",
            "         29799,   286],\n",
            "        [15496,    11,   314,  1101,   257,  3303,  2746,    11,   290,    11,\n",
            "         41348,   262,   317,   281,  7306,  7176,    11,   281, 25412,    11,\n",
            "          2398,   286,   286,    11,    11,    13,   290,    11,    11,    11,\n",
            "           290, 41348],\n",
            "        [15496,    11,   314,  1101,   257,  3303,  2746,    11,    13,  2097,\n",
            "          5642,   286,    11,   262,    13,   290,   290,  5642,    11,    11,\n",
            "          7565, 40705,   198,   290, 33131,   284,   355,    13, 21111,   290,\n",
            "           290, 27937]], device='cuda:0')\n",
            "rank 0 sample 0: Hello, I'm a language model, A, a,. such for- ch15, conventional the in skiing for, of15 of the\n",
            ", for\n",
            "rank 0 sample 1: Hello, I'm a language model, beautifully cryptographic ch, and, the request, and Kids 1951. of feeling of. and is. cryptographic the Randall of\n",
            "rank 0 sample 2: Hello, I'm a language model, and, skiing the A an ideal hopes, an configurations,org of of,,. and,,, and skiing\n",
            "rank 0 sample 3: Hello, I'm a language model,. House manner of, the. and and manner,, vary cryptographic\n",
            " and gastro to as.Camp and and 1951\n",
            "step 50 | loss: 9.469453811645508 | lr: 1.0699e-04 | norm: 8.2093 | dt=133059.39ms | 3940.26 tokens/sec\n",
            "step 51 | loss: 9.431706428527832 | lr: 1.0909e-04 | norm: 6.6175 | dt=24405.06ms | 21482.76 tokens/sec\n",
            "step 52 | loss: 9.45513916015625 | lr: 1.1119e-04 | norm: 5.6266 | dt=24385.03ms | 21500.41 tokens/sec\n",
            "step 53 | loss: 9.459357261657715 | lr: 1.1329e-04 | norm: 7.4186 | dt=24259.39ms | 21611.75 tokens/sec\n",
            "step 54 | loss: 9.428733825683594 | lr: 1.1538e-04 | norm: 5.1613 | dt=24179.40ms | 21683.26 tokens/sec\n",
            "tokens: tensor([[15496,    11,   314,  1101,   257,  3303,  2746,    11,  4203,    11,\n",
            "           281,    11,   262,   281,   284,  2097,  4536,  4536,  1904,  4536,\n",
            "            11,   355, 10248,   284,   262,    11, 17707,   287,    13,   284,\n",
            "           262,   284],\n",
            "        [15496,    11,   314,  1101,   257,  3303,  2746,    11, 25412,  7587,\n",
            "          7582,    11,    13,    11,   290, 12725,    11,    13,  2282,   373,\n",
            "           262,  3015,  2282,   286,    11,    13,  1755,   262,   903,   290,\n",
            "           726,    13],\n",
            "        [15496,    11,   314,  1101,   257,  3303,  2746,    11,   262,   262,\n",
            "          3011,  3011,  3608,   281,  1337,  1263,    11,  2097,  1904,    11,\n",
            "           257,   286,   286,   262,   329,    11,   262,   262,   262,   262,\n",
            "            11,  4536],\n",
            "        [15496,    11,   314,  1101,   257,  3303,  2746,    11,   262, 17707,\n",
            "         15000,    11,    11,    11,   262,    13,   262, 15572,    11,    11,\n",
            "          4536,  7306,   287,    13,  4343,   329,   318,   262,  1755,    13,\n",
            "           262, 27069]], device='cuda:0')\n",
            "rank 0 sample 0: Hello, I'm a language model, feeling, an, the an to House prices pricesuse prices, asGood to the, tightly in. to the to\n",
            "rank 0 sample 1: Hello, I'm a language model, configurations processing shell,., and attracted,. saying was the vote saying of,. night theble andoy.\n",
            "rank 0 sample 2: Hello, I'm a language model, the the gets gets cool an care big, Houseuse, a of of the for, the the the the, prices\n",
            "rank 0 sample 3: Hello, I'm a language model, the tightly consume,,, the. the illegally,, prices ideal in. 2007 for is the night. the drastic\n",
            "step 55 | loss: 9.45749282836914 | lr: 1.1748e-04 | norm: 5.1976 | dt=24430.88ms | 21460.06 tokens/sec\n",
            "step 56 | loss: 9.430989265441895 | lr: 1.1958e-04 | norm: 6.4717 | dt=24219.42ms | 21647.42 tokens/sec\n",
            "step 57 | loss: 9.370326042175293 | lr: 1.2168e-04 | norm: 5.6462 | dt=24216.67ms | 21649.88 tokens/sec\n",
            "step 58 | loss: 9.341948509216309 | lr: 1.2378e-04 | norm: 5.9635 | dt=24224.01ms | 21643.32 tokens/sec\n",
            "step 59 | loss: 9.318379402160645 | lr: 1.2587e-04 | norm: 6.7351 | dt=24236.45ms | 21632.21 tokens/sec\n",
            "tokens: tensor([[15496,    11,   314,  1101,   257,  3303,  2746,    11,  1744,    11,\n",
            "           726,    11,   262,  5693,   329,    12, 28810,  1230, 23724,   991,\n",
            "           262,  3188, 10224,   257,    11,   286, 35433,   286,    13,   257,\n",
            "            11,   257],\n",
            "        [15496,    11,   314,  1101,   257,  3303,  2746,    11,  2666,   355,\n",
            "           873,    11,    13,    11,   290, 23724,    11,   262, 23724,   595,\n",
            "            13,   286,   873,   286,   262,    13,  7815,    13,   287,   290,\n",
            "           345,   286],\n",
            "        [15496,    11,   314,  1101,   257,  3303,  2746,    11,   262,    11,\n",
            "         28810,   290,  1230,   884,  2292,  7306,    11,   884,  1230,    11,\n",
            "           726,   286,   286,    11,   318,    13,   262,    11,    11,    11,\n",
            "           262,  7306],\n",
            "        [15496,    11,   314,  1101,   257,  3303,  2746,    11,    13,  2292,\n",
            "            35,   286,    11,    11,   262,    13,   262,  2666,    11,    11,\n",
            "         23724,   884,   257,   262, 23724,   284,   198,   262,   636,   262,\n",
            "            13,   636]], device='cuda:0')\n",
            "rank 0 sample 0: Hello, I'm a language model, possible,oy, the Foundation for- discrete government evacuated still the document conventional a, ofExplore of. a, a\n",
            "rank 0 sample 1: Hello, I'm a language model, leave asics,., and evacuated, the evacuated dis. ofics of the. stone. in and you of\n",
            "rank 0 sample 2: Hello, I'm a language model, the, discrete and government such position ideal, such government,oy of of, is. the,,, the ideal\n",
            "rank 0 sample 3: Hello, I'm a language model,. positionD of,, the. the leave,, evacuated such a the evacuated to\n",
            " the part the. part\n",
            "step 60 | loss: 9.291879653930664 | lr: 1.2797e-04 | norm: 5.8755 | dt=24464.25ms | 21430.78 tokens/sec\n",
            "step 61 | loss: 9.273992538452148 | lr: 1.3007e-04 | norm: 5.6986 | dt=24205.94ms | 21659.48 tokens/sec\n",
            "step 62 | loss: 9.275248527526855 | lr: 1.3217e-04 | norm: 6.7577 | dt=24250.74ms | 21619.46 tokens/sec\n",
            "step 63 | loss: 9.25552749633789 | lr: 1.3427e-04 | norm: 5.8201 | dt=24207.69ms | 21657.91 tokens/sec\n",
            "step 64 | loss: 9.254786491394043 | lr: 1.3636e-04 | norm: 7.1198 | dt=24257.08ms | 21613.82 tokens/sec\n",
            "tokens: tensor([[15496,    11,   314,  1101,   257,  3303,  2746,    11,   317,    11,\n",
            "          2097,    11,    13,   284,   329,  2398,  6693,   726,  7527,  8720,\n",
            "            13,   257, 18180,   329,    11,   286,   317,   287,   262,    13,\n",
            "            13,   286],\n",
            "        [15496,    11,   314,  1101,   257,  3303,  2746,    11,  6693,  1813,\n",
            "          1286,    11,   262,    11,   290,  8720,    11,   262,  7527,  1263,\n",
            "            13,   286,  3938,   286,    13,   262,  3011,    13,   257,   290,\n",
            "          7176,   262],\n",
            "        [15496,    11,   314,  1101,   257,  3303,  2746,    11,    13,    13,\n",
            "          7587,   290,   355,   884,   317, 13020,    13,  2097,  1286,    13,\n",
            "           287,   286,   286,    13,    13,    11,    13,    13,    13,    13,\n",
            "            11,  3011],\n",
            "        [15496,    11,   314,  1101,   257,  3303,  2746,    11,   262,  1263,\n",
            "           355,   290,    13,   290,    11,   262,   262, 10248,    13,    13,\n",
            "         15572,   281,   198,   262,  4203,   284,   318,    11,   726,   262,\n",
            "           262,   726]], device='cuda:0')\n",
            "rank 0 sample 0: Hello, I'm a language model, A, House,. to fororg discussedoyrich officially. a rivers for, of A in the.. of\n",
            "rank 0 sample 1: Hello, I'm a language model, discussed givenately, the, and officially, therich big. of fully of. the gets. a and hopes the\n",
            "rank 0 sample 2: Hello, I'm a language model,.. processing and as such A grain. Houseately. in of of..,...., gets\n",
            "rank 0 sample 3: Hello, I'm a language model, the big as and. and, the theGood.. illegally an\n",
            " the feeling to is,oy the theoy\n",
            "step 65 | loss: 9.253661155700684 | lr: 1.3846e-04 | norm: 6.3819 | dt=24470.22ms | 21425.56 tokens/sec\n",
            "step 66 | loss: 9.247185707092285 | lr: 1.4056e-04 | norm: 8.8417 | dt=24250.61ms | 21619.58 tokens/sec\n",
            "step 67 | loss: 9.197826385498047 | lr: 1.4266e-04 | norm: 9.3544 | dt=24184.50ms | 21678.68 tokens/sec\n",
            "step 68 | loss: 9.23913860321045 | lr: 1.4476e-04 | norm: 9.6841 | dt=24236.16ms | 21632.47 tokens/sec\n",
            "step 69 | loss: 9.182879447937012 | lr: 1.4685e-04 | norm: 6.9563 | dt=24211.33ms | 21654.66 tokens/sec\n",
            "tokens: tensor([[15496,    11,   314,  1101,   257,  3303,  2746,    11,   884,   262,\n",
            "           287,   262,    13,  2282,   284,  2282,  6306,  4958,   262, 10846,\n",
            "            13,   383,   357,   284,   262,   286,   726,   286,    11,    13,\n",
            "            13,    11],\n",
            "        [15496,    11,   314,  1101,   257,  3303,  2746,    11, 25412,   790,\n",
            "         25412,   262,    11,   262,   290,  2398,   262,    11,  4958,  5693,\n",
            "            13,   198,  1103,   286,    13,   262, 25412,    13,  3608,   290,\n",
            "          2398,    11],\n",
            "        [15496,    11,   314,  1101,   257,  3303,  2746,    11,    11,   262,\n",
            "         25412,   290,  4958,  7306,   357,   726,    13,   318,  4082,   262,\n",
            "           287,   286,   286,   262,   281,    11,    13,    13, 10087,    13,\n",
            "            11,  2097],\n",
            "        [15496,    11,   314,  1101,   257,  3303,  2746,    11,    13,   726,\n",
            "         10846,   286,   262,   262,    11,    13,   262, 10101,   262,   262,\n",
            "          7674,  7306,   329,    11,   991,   281,  7565,    13,  5693,    11,\n",
            "            13,   790]], device='cuda:0')\n",
            "rank 0 sample 0: Hello, I'm a language model, such the in the. saying to saying experiment master the lady. The ( to the ofoy of,..,\n",
            "rank 0 sample 1: Hello, I'm a language model, configurations every configurations the, the andorg the, master Foundation.\n",
            " real of. the configurations. cool andorg,\n",
            "rank 0 sample 2: Hello, I'm a language model,, the configurations and master ideal (oy. is birth the in of of the an,.. birds., House\n",
            "rank 0 sample 3: Hello, I'm a language model,.oy lady of the the,. the temperatures the the territory ideal for, still an vary. Foundation,. every\n",
            "step 70 | loss: 9.182336807250977 | lr: 1.4895e-04 | norm: 7.1246 | dt=24473.47ms | 21422.71 tokens/sec\n",
            "step 71 | loss: 9.173807144165039 | lr: 1.5105e-04 | norm: 7.0446 | dt=24205.34ms | 21660.02 tokens/sec\n",
            "step 72 | loss: 9.170852661132812 | lr: 1.5315e-04 | norm: 7.3636 | dt=24201.19ms | 21663.73 tokens/sec\n",
            "step 73 | loss: 9.13185977935791 | lr: 1.5524e-04 | norm: 7.7003 | dt=24207.17ms | 21658.37 tokens/sec\n",
            "step 74 | loss: 9.126238822937012 | lr: 1.5734e-04 | norm: 10.5676 | dt=24230.29ms | 21637.71 tokens/sec\n",
            "tokens: tensor([[15496,    11,   314,  1101,   257,  3303,  2746,    11,    11,    11,\n",
            "           257,    11,    13,   318,   329,  5693,  4203,  6338,    11, 16083,\n",
            "            13,   281, 11841,   329,    11,   286,  4404,   286,   262,    13,\n",
            "            11,   329],\n",
            "        [15496,    11,   314,  1101,   257,  3303,  2746,    11,  2282,  1813,\n",
            "          6903,    11,   262,    11,   290,  1263,    11,   262,  1230,  6338,\n",
            "            13,   198,   636,   286,    13,   262,  4133,    13,   257,   290,\n",
            "          1263,   286],\n",
            "        [15496,    11,   314,  1101,   257,  3303,  2746,    11,    13,    11,\n",
            "          4133,   290,  2282,    12,  6306,  2282,    11,   257,  1230,    11,\n",
            "           198,   286,   286,    11,    11,    13,    13,    11,    11,    11,\n",
            "            13,  4404],\n",
            "        [15496,    11,   314,  1101,   257,  3303,  2746,    11,   262,  1200,\n",
            "           595,   286,    11,    11,    13,   884,   262, 16083,    11,    11,\n",
            "          1813,  7565,    11,   262,   636,   287,  2097,    13,  4133,   262,\n",
            "           262, 18180]], device='cuda:0')\n",
            "rank 0 sample 0: Hello, I'm a language model,,, a,. is for Foundation feeling automatically, traditionally. an dirty for, of defend of the., for\n",
            "rank 0 sample 1: Hello, I'm a language model, saying given portion, the, and big, the government automatically.\n",
            " part of. the resources. a and big of\n",
            "rank 0 sample 2: Hello, I'm a language model,., resources and saying- experiment saying, a government,\n",
            " of of,,..,,,. defend\n",
            "rank 0 sample 3: Hello, I'm a language model, the child dis of,,. such the traditionally,, given vary, the part in House. resources the the rivers\n",
            "step 75 | loss: 9.081073760986328 | lr: 1.5944e-04 | norm: 9.1489 | dt=24406.45ms | 21481.54 tokens/sec\n",
            "step 76 | loss: 9.142800331115723 | lr: 1.6154e-04 | norm: 9.7835 | dt=24231.66ms | 21636.49 tokens/sec\n",
            "step 77 | loss: 9.104442596435547 | lr: 1.6364e-04 | norm: 8.7370 | dt=24188.30ms | 21675.27 tokens/sec\n",
            "step 78 | loss: 9.068305969238281 | lr: 1.6573e-04 | norm: 9.4484 | dt=24136.30ms | 21721.97 tokens/sec\n",
            "step 79 | loss: 9.092934608459473 | lr: 1.6783e-04 | norm: 11.2692 | dt=24192.68ms | 21671.34 tokens/sec\n",
            "tokens: tensor([[15496,    11,   314,  1101,   257,  3303,  2746,    11,  7176,   198,\n",
            "           257,   198,    11,   329,    12,  4343, 10224,   278,   198,  5440,\n",
            "            11,  1400,  3307,    12,   198,   262, 10224,   383,   290,   383,\n",
            "           198,    12],\n",
            "        [15496,    11,   314,  1101,   257,  3303,  2746,    11,   278,  6842,\n",
            "          7306,   198,    13,   198,   290,  5338,   198,    13,  3307,  2138,\n",
            "            11,    12,   278,   262,    11,    13,   198,    11,  1400,   290,\n",
            "          7306,   262],\n",
            "        [15496,    11,   314,  1101,   257,  3303,  2746,    11,   198,   198,\n",
            "         13399,  6842, 15000, 15000,   373,   636,   198,   884,   726,   198,\n",
            "           329,   262,   290,   198,   198,    11,   198,   198,   198,   198,\n",
            "            11,  5749],\n",
            "        [15496,    11,   314,  1101,   257,  3303,  2746,    11,    12,  7306,\n",
            "          3443,   262,   198,   198,    11,   636,    13,  3463,   198,   198,\n",
            "           475,   884,   198,    13, 10248,   383,  5642,  7306, 12264,   198,\n",
            "            13, 15000]], device='cuda:0')\n",
            "rank 0 sample 0: Hello, I'm a language model, hopes\n",
            " a\n",
            ", for- 2007 conventionaling\n",
            " planet, No details-\n",
            " the conventional The and The\n",
            "-\n",
            "rank 0 sample 1: Hello, I'm a language model,ing bear ideal\n",
            ".\n",
            " and Who\n",
            ". details rather,-ing the,.\n",
            ", No and ideal the\n",
            "rank 0 sample 2: Hello, I'm a language model,\n",
            "\n",
            " texts bear consume consume was part\n",
            " suchoy\n",
            " for the and\n",
            "\n",
            ",\n",
            "\n",
            "\n",
            "\n",
            ", bigger\n",
            "rank 0 sample 3: Hello, I'm a language model,- ideal finally the\n",
            "\n",
            ", part. weight\n",
            "\n",
            " but such\n",
            ".Good The manner ideal clicking\n",
            ". consume\n",
            "step 80 | loss: 9.235873222351074 | lr: 1.6993e-04 | norm: 18.8188 | dt=24488.26ms | 21409.77 tokens/sec\n",
            "step 81 | loss: 9.093512535095215 | lr: 1.7203e-04 | norm: 12.6275 | dt=24104.69ms | 21750.46 tokens/sec\n",
            "step 82 | loss: 9.31662654876709 | lr: 1.7413e-04 | norm: 15.0750 | dt=24054.17ms | 21796.14 tokens/sec\n",
            "step 83 | loss: 9.446807861328125 | lr: 1.7622e-04 | norm: 17.2090 | dt=24175.82ms | 21686.46 tokens/sec\n",
            "step 84 | loss: 9.221882820129395 | lr: 1.7832e-04 | norm: 14.4085 | dt=24230.79ms | 21637.26 tokens/sec\n",
            "tokens: tensor([[15496,    11,   314,  1101,   257,  3303,  2746,    11,  1255,   262,\n",
            "           318,   262,    13,   318,   286,  5693,  4894,   287,   262,  5447,\n",
            "            13,   257,  2097,   286,   262,   198,  1912,   329,    11,   329,\n",
            "           262,   286],\n",
            "        [15496,    11,   314,  1101,   257,  3303,  2746,    11,   636,   534,\n",
            "          4894,   262,    11,   262,   290,  6842,   262,    11,  2643, 10224,\n",
            "            13,    76,   281,   290,    13,   198, 10224,    13,  4197,   198,\n",
            "            76,   198],\n",
            "        [15496,    11,   314,  1101,   257,  3303,  2746,    11,    13,   262,\n",
            "          1262, 10224,   873, 11841,  1912,   351,   262,    50,   873,   262,\n",
            "          2282,   290,   198,   262,   262,    11,    11,   262,   262,   262,\n",
            "            13,   287],\n",
            "        [15496,    11,   314,  1101,   257,  3303,  2746,    11,   262,  3608,\n",
            "           645,   290,   262,   262,    13,   198,    11,  5447,   262,   262,\n",
            "          1912,    50,   262,    11, 50256,  2282,    50,  1286, 10224,   262,\n",
            "            11,   287]], device='cuda:0')\n",
            "rank 0 sample 0: Hello, I'm a language model, result the is the. is of Foundation heat in the defined. a House of the\n",
            " based for, for the of\n",
            "rank 0 sample 1: Hello, I'm a language model, part your heat the, the and bear the, statement conventional.m an and.\n",
            " conventional. fit\n",
            "m\n",
            "\n",
            "rank 0 sample 2: Hello, I'm a language model,. the using conventionalics dirty based with theSics the saying and\n",
            " the the,, the the the. in\n",
            "rank 0 sample 3: Hello, I'm a language model, the cool no and the the.\n",
            ", defined the the basedS the,<|endoftext|> sayingSately conventional the, in\n",
            "step 85 | loss: 9.197587966918945 | lr: 1.8042e-04 | norm: 12.3855 | dt=24378.43ms | 21506.23 tokens/sec\n",
            "step 86 | loss: 9.1841402053833 | lr: 1.8252e-04 | norm: 12.0540 | dt=24086.60ms | 21766.79 tokens/sec\n",
            "step 87 | loss: 9.204880714416504 | lr: 1.8462e-04 | norm: 12.7633 | dt=24158.72ms | 21701.82 tokens/sec\n",
            "step 88 | loss: 9.17361831665039 | lr: 1.8671e-04 | norm: 13.8807 | dt=24152.42ms | 21707.47 tokens/sec\n",
            "step 89 | loss: 9.089494705200195 | lr: 1.8881e-04 | norm: 12.4861 | dt=24119.61ms | 21737.00 tokens/sec\n",
            "tokens: tensor([[15496,    11,   314,  1101,   257,  3303,  2746,    11,    11,    11,\n",
            "           284,    11,    13,   318,   329,   287,  4380, 11658,    11,  3608,\n",
            "            13,  7587,  3011,   198,    11,   286,  4380,    12,   262,    12,\n",
            "            11,   329],\n",
            "        [15496,    11,   314,  1101,   257,  3303,  2746,    11,   264,   345,\n",
            "          4343,    11,   262,    11,   290,  1103,    11,   262,  4380,   694,\n",
            "            13,   198,  2581,   286,    13,   262, 15964,    13,  7815,   290,\n",
            "            11,    11],\n",
            "        [15496,    11,   314,  1101,   257,  3303,  2746,    11,    13,    11,\n",
            "          9363,   694,  3011,  4133,  8978,   264,    11,  4133,   503,    11,\n",
            "           257,   286,   286,    11,    11,   262,   262,    11,    11,    11,\n",
            "            13,  4380],\n",
            "        [15496,    11,   314,  1101,   257,  3303,  2746,    11,    11, 15964,\n",
            "            11,    11,    11,    11,    13,   694,   262, 10478,    11,    11,\n",
            "          3463,  4133,    11,   262,  1895,    12,   373,  7346,   694,    11,\n",
            "           262, 11658]], device='cuda:0')\n",
            "rank 0 sample 0: Hello, I'm a language model,,, to,. is for in People lessons, cool. processing gets\n",
            ", of People- the-, for\n",
            "rank 0 sample 1: Hello, I'm a language model, s you 2007, the, and real, the Peopleck.\n",
            " request of. the measuring. stone and,,\n",
            "rank 0 sample 2: Hello, I'm a language model,., Storeck gets resources reaching s, resources out, a of of,, the the,,,. People\n",
            "rank 0 sample 3: Hello, I'm a language model,, measuring,,,,.ck the Help,, weight resources, the access- was surroundingck, the lessons\n",
            "step 90 | loss: 9.030476570129395 | lr: 1.9091e-04 | norm: 11.8407 | dt=24289.09ms | 21585.33 tokens/sec\n",
            "step 91 | loss: 9.01966667175293 | lr: 1.9301e-04 | norm: 11.9891 | dt=24054.07ms | 21796.23 tokens/sec\n",
            "step 92 | loss: 8.995006561279297 | lr: 1.9510e-04 | norm: 13.5831 | dt=24067.34ms | 21784.21 tokens/sec\n",
            "step 93 | loss: 8.991008758544922 | lr: 1.9720e-04 | norm: 11.6866 | dt=24023.96ms | 21823.54 tokens/sec\n",
            "step 94 | loss: 8.933362007141113 | lr: 1.9930e-04 | norm: 11.8404 | dt=24002.21ms | 21843.32 tokens/sec\n",
            "tokens: tensor([[15496,    11,   314,  1101,   257,  3303,  2746,    11,   530,    13,\n",
            "          5952,    13,    11,   257,   329,   636,   318,   318,    13,   383,\n",
            "            11,  4133,   318,   329,    13,   290,  1263,   287,   262,    11,\n",
            "            11,   262],\n",
            "        [15496,    11,   314,  1101,   257,  3303,  2746,    11,    13,   690,\n",
            "          6338,    13,   262,    13,   198,  3068,    13,   262,   351,  5693,\n",
            "            11,   329,   318,   198,    11,   262,  7565,    11,  1314,   290,\n",
            "          3608,   262],\n",
            "        [15496,    11,   314,  1101,   257,  3303,  2746,    11,    13,    13,\n",
            "         13020,  5693,   595,   284,  2398,   595,    13,  7176,    11,    13,\n",
            "            12,   198,   290,    13,    13,    11,   262,    13,    13,    13,\n",
            "            11,   690],\n",
            "        [15496,    11,   314,  1101,   257,  3303,  2746,    11,   262,   690,\n",
            "          3443,   198,    13,    13,    11,   262,   262,  2099,    13,    13,\n",
            "           595,   884,   286,   262,  2099,   287,  4203,    11,  7565,   262,\n",
            "           262,  3938]], device='cuda:0')\n",
            "rank 0 sample 0: Hello, I'm a language model, one. conducted., a for part is is. The, resources is for. and big in the,, the\n",
            "rank 0 sample 1: Hello, I'm a language model,.vers automatically. the.\n",
            " mention. the with Foundation, for is\n",
            ", the vary,15 and cool the\n",
            "rank 0 sample 2: Hello, I'm a language model,.. grain Foundation dis toorg dis. hopes,.-\n",
            " and.., the...,vers\n",
            "rank 0 sample 3: Hello, I'm a language model, thevers finally\n",
            ".., the the type.. dis such of the type in feeling, vary the the fully\n",
            "step 95 | loss: 8.95414924621582 | lr: 2.0140e-04 | norm: 12.8175 | dt=24265.27ms | 21606.52 tokens/sec\n",
            "step 96 | loss: 8.924295425415039 | lr: 2.0350e-04 | norm: 12.0842 | dt=23982.22ms | 21861.53 tokens/sec\n",
            "step 97 | loss: 8.887046813964844 | lr: 2.0559e-04 | norm: 11.2839 | dt=23998.72ms | 21846.50 tokens/sec\n",
            "step 98 | loss: 8.905921936035156 | lr: 2.0769e-04 | norm: 12.1534 | dt=23984.83ms | 21859.15 tokens/sec\n",
            "step 99 | loss: 8.889297485351562 | lr: 2.0979e-04 | norm: 13.0597 | dt=23986.64ms | 21857.50 tokens/sec\n",
            "validation loss: 8.8553\n",
            "helloswag accuracy: 2585/10042 0.2574\n",
            "tokens: tensor([[15496,    11,   314,  1101,   257,  3303,  2746,    11,  1654,    11,\n",
            "           284,    11,   262,   287,   329,  2398,   458,  5693,   475,  7587,\n",
            "           262,   636,  6693,   329,   262,   286,  2190,   286,    13,    11,\n",
            "            11,    13],\n",
            "        [15496,    11,   314,  1101,   257,  3303,  2746,    11,   699,  2282,\n",
            "          6842,   262,    13,    13,   290,  2190,    11,    13,  7565,   345,\n",
            "           262,   329,  7565,   286,    11,    13,   345,    11,  1103,   290,\n",
            "          2548,   286],\n",
            "        [15496,    11,   314,  1101,   257,  3303,  2746,    11,   262,   262,\n",
            "           884,   290, 22395,   257, 10416,  6693,   262,  7176,   609,    11,\n",
            "           281,   286,   286,   262,   284,    13,   262,   262,   262,   262,\n",
            "            11,  2250],\n",
            "        [15496,    11,   314,  1101,   257,  3303,  2746,    11,    13,   383,\n",
            "          7587,   286,   262,   262,    11,    13,   262,  7587,    11,    11,\n",
            "         18180, 10224,   198,    13, 18180,   318,  7176,   262,    12,    13,\n",
            "           262,  5693]], device='cuda:0')\n",
            "rank 0 sample 0: Hello, I'm a language model, sure, to, the in fororg pl Foundation but processing the part discussed for the of treat of.,,.\n",
            "rank 0 sample 1: Hello, I'm a language model,ious saying bear the.. and treat,. vary you the for vary of,. you, real and38 of\n",
            "rank 0 sample 2: Hello, I'm a language model, the the such and Introduction a confused discussed the hopes Ch, an of of the to. the the the the, hours\n",
            "rank 0 sample 3: Hello, I'm a language model,. The processing of the the,. the processing,, rivers conventional\n",
            ". rivers is hopes the-. the Foundation\n",
            "step 100 | loss: 8.859647750854492 | lr: 2.1189e-04 | norm: 11.7750 | dt=131854.60ms | 3976.26 tokens/sec\n",
            "step 101 | loss: 8.8533296585083 | lr: 2.1399e-04 | norm: 13.0240 | dt=23996.16ms | 21848.83 tokens/sec\n",
            "step 102 | loss: 8.881321907043457 | lr: 2.1608e-04 | norm: 12.5066 | dt=23978.25ms | 21865.15 tokens/sec\n",
            "step 103 | loss: 8.833883285522461 | lr: 2.1818e-04 | norm: 11.9581 | dt=23989.63ms | 21854.78 tokens/sec\n",
            "step 104 | loss: 8.831245422363281 | lr: 2.2028e-04 | norm: 13.3482 | dt=23975.38ms | 21867.77 tokens/sec\n",
            "tokens: tensor([[15496,    11,   314,  1101,   257,  3303,  2746,    11,    11,    11,\n",
            "           287,    11,    13,   884,   198,   318,  4894,  4894,    11,  2282,\n",
            "            13,  4133, 50256,   198,    11,   286,  5693,   257,   262,    13,\n",
            "            13,   286],\n",
            "        [15496,    11,   314,  1101,   257,  3303,  2746,    11,  2499,  1744,\n",
            "           690,    11,   262,    11,   290,  2651,    11,   262,  4894,   373,\n",
            "            13,   286, 19717,   286,    13,   262,  1286,    13,   645,   290,\n",
            "          3307,   262],\n",
            "        [15496,    11,   314,  1101,   257,  3303,  2746,    11,    13,    13,\n",
            "         13020,   290, 13020,  7565,   264, 50256,    11,  2398,    13,    11,\n",
            "            12,   286,   286,    11,    11,    13,    11,    11,    11,    11,\n",
            "            13,   852],\n",
            "        [15496,    11,   314,  1101,   257,  3303,  2746,    11,   262,  1744,\n",
            "          3307,   286,    11,    11,    13,   262,   262,   690,    11,    11,\n",
            "          4203,  2398,   329,   262,   264,   257,  7565,    13,   373,   262,\n",
            "           262,  4088]], device='cuda:0')\n",
            "rank 0 sample 0: Hello, I'm a language model,,, in,. such\n",
            " is heat heat, saying. resources<|endoftext|>\n",
            ", of Foundation a the.. of\n",
            "rank 0 sample 1: Hello, I'm a language model, works possiblevers, the, and forward, the heat was. of Agriculture of. theately. no and details the\n",
            "rank 0 sample 2: Hello, I'm a language model,.. grain and grain vary s<|endoftext|>,org.,- of of,,.,,,,. being\n",
            "rank 0 sample 3: Hello, I'm a language model, the possible details of,,. the thevers,, feelingorg for the s a vary. was the the memory\n",
            "step 105 | loss: 8.79775333404541 | lr: 2.2238e-04 | norm: 12.1264 | dt=24192.18ms | 21671.79 tokens/sec\n",
            "step 106 | loss: 8.8302001953125 | lr: 2.2448e-04 | norm: 12.6391 | dt=23994.31ms | 21850.52 tokens/sec\n",
            "step 107 | loss: 8.808606147766113 | lr: 2.2657e-04 | norm: 12.1377 | dt=23960.07ms | 21881.74 tokens/sec\n",
            "step 108 | loss: 8.786437034606934 | lr: 2.2867e-04 | norm: 12.5981 | dt=23972.82ms | 21870.10 tokens/sec\n",
            "step 109 | loss: 8.76819133758545 | lr: 2.3077e-04 | norm: 13.2719 | dt=23995.55ms | 21849.38 tokens/sec\n",
            "tokens: tensor([[15496,    11,   314,  1101,   257,  3303,  2746,    11,  2398,    11,\n",
            "           318,    11,    13,   318,   287,   284,  6842,   873,   262,  6842,\n",
            "           262,  1262,  6688,   287,    11,   286,  2282,   329,   290,    13,\n",
            "            13,   198],\n",
            "        [15496,    11,   314,  1101,   257,  3303,  2746,    11,    13,  4809,\n",
            "          2753,    13,   290,   290,   262,  3307,    13,   290, 13312,  5693,\n",
            "            11,   287,  2097,   286,    11,   290,  5693,    11,  1262,   262,\n",
            "           262,   290],\n",
            "        [15496,    11,   314,  1101,   257,  3303,  2746,    11,   290,   290,\n",
            "         13312,   262,    76,  7565,  2097,   351,    13,  3068,  2097,    11,\n",
            "           257,   286,   262,    13,   262,   262,   262,    13,    13,    13,\n",
            "            11,   281],\n",
            "        [15496,    11,   314,  1101,   257,  3303,  2746,    11,    13,  4809,\n",
            "           884,   262,    13,   262,    11,   290,    11,  2398,    13,    13,\n",
            "          7306,  7565,   262,   262,  9332,   262,  3068,    11, 10224,   290,\n",
            "            11,   357]], device='cuda:0')\n",
            "rank 0 sample 0: Hello, I'm a language model,org, is,. is in to bearics the bear the using explains in, of saying for and..\n",
            "\n",
            "rank 0 sample 1: Hello, I'm a language model,. Service takes. and and the details. and developments Foundation, in House of, and Foundation, using the the and\n",
            "rank 0 sample 2: Hello, I'm a language model, and and developments them vary House with. mention House, a of the. the the the..., an\n",
            "rank 0 sample 3: Hello, I'm a language model,. Service such the. the, and,org.. ideal vary the the efficiency the mention, conventional and, (\n",
            "step 110 | loss: 8.709355354309082 | lr: 2.3287e-04 | norm: 14.1818 | dt=24200.31ms | 21664.52 tokens/sec\n",
            "step 111 | loss: 8.722472190856934 | lr: 2.3497e-04 | norm: 13.0515 | dt=23956.04ms | 21885.42 tokens/sec\n",
            "step 112 | loss: 8.724376678466797 | lr: 2.3706e-04 | norm: 14.5592 | dt=24001.24ms | 21844.21 tokens/sec\n",
            "step 113 | loss: 8.732945442199707 | lr: 2.3916e-04 | norm: 13.8501 | dt=23977.56ms | 21865.78 tokens/sec\n",
            "step 114 | loss: 8.753912925720215 | lr: 2.4126e-04 | norm: 14.9933 | dt=23903.45ms | 21933.57 tokens/sec\n",
            "tokens: tensor([[15496,    11,   314,  1101,   257,  3303,  2746,    11,    13,    13,\n",
            "            12,    13,    11,   198,   329,  3011,   260,  7085,    13,  1654,\n",
            "            11,    50,   260,   329,    13,   286,  1309,   286,   262,   262,\n",
            "            13,   329],\n",
            "        [15496,    11,   314,  1101,   257,  3303,  2746,    11,   262,   340,\n",
            "           378,    13,   262,    13,   290,   775,    13,   262,  7306,   873,\n",
            "            11,   329,  1263,   286,   262,    11,  2398,   262,    50,   290,\n",
            "            13,   286],\n",
            "        [15496,    11,   314,  1101,   257,  3303,  2746,    11,    11,    13,\n",
            "          1596,   290,   260,   355,  7522,   260,    13,  5693, 10101,    13,\n",
            "           318,   286,   286,    13,    13,   262,    11,    13,    13,    13,\n",
            "            11,  2581],\n",
            "        [15496,    11,   314,  1101,   257,  3303,  2746,    11,   262,   340,\n",
            "            13,   286,    13,    13,    11,   262,    11,  6306,    13,    13,\n",
            "            13,  5693,    13,   262,    21,   318,   355,   262,  2398,   262,\n",
            "            11,   340]], device='cuda:0')\n",
            "rank 0 sample 0: Hello, I'm a language model,..-.,\n",
            " for getsreMany. sure,Sre for. of let of the the. for\n",
            "rank 0 sample 1: Hello, I'm a language model, the itate. the. and We. the idealics, for big of the,org theS and. of\n",
            "rank 0 sample 2: Hello, I'm a language model,,. 17 andre as honorre. Foundation temperatures. is of of.. the,..., request\n",
            "rank 0 sample 3: Hello, I'm a language model, the it. of.., the, experiment... Foundation. the6 is as theorg the, it\n",
            "step 115 | loss: 8.753884315490723 | lr: 2.4336e-04 | norm: 14.6679 | dt=24151.24ms | 21708.53 tokens/sec\n",
            "step 116 | loss: 8.760313034057617 | lr: 2.4545e-04 | norm: 14.8002 | dt=24023.67ms | 21823.81 tokens/sec\n",
            "step 117 | loss: 8.711484909057617 | lr: 2.4755e-04 | norm: 15.2531 | dt=24020.68ms | 21826.53 tokens/sec\n",
            "step 118 | loss: 8.728920936584473 | lr: 2.4965e-04 | norm: 16.0450 | dt=23954.26ms | 21887.05 tokens/sec\n",
            "step 119 | loss: 8.728771209716797 | lr: 2.5175e-04 | norm: 15.8728 | dt=23919.52ms | 21918.84 tokens/sec\n",
            "tokens: tensor([[15496,    11,   314,  1101,   257,  3303,  2746,    11,    11,    11,\n",
            "           318,    11,    13,  7176,   286,  7176,  5086,   373,    11,  4343,\n",
            "            13,  4197,   264,   286,    11,    13,  3608,   287,   262,    13,\n",
            "            13,   262],\n",
            "        [15496,    11,   314,  1101,   257,  3303,  2746,    11,   264,   873,\n",
            "          6338,    11,   262,    11,   290,  4104,    11,   262,  2282,  3938,\n",
            "            13,   198,  3164,   257,    13,   262,   284,    13,  4197,   290,\n",
            "           530,   262],\n",
            "        [15496,    11,   314,  1101,   257,  3303,  2746,    11,    13,    13,\n",
            "           636,   636,   654,  2444,  3164,   820,    11,  2398,    13,    11,\n",
            "           198,   257,   257,    11,    11,    13,    11,    11,    11,    11,\n",
            "            13,  2292],\n",
            "        [15496,    11,   314,  1101,   257,  3303,  2746,    11,   262,   873,\n",
            "          4104,    11,    11,    11,    13,   262,   262,   503,    11,    11,\n",
            "          3164,  2398,   281,   262,  7306,   287,  2651,    13,  3938,   262,\n",
            "           262,  2292]], device='cuda:0')\n",
            "rank 0 sample 0: Hello, I'm a language model,,, is,. hopes of hopes allowing was, 2007. fit s of,. cool in the.. the\n",
            "rank 0 sample 1: Hello, I'm a language model, sics automatically, the, and spread, the saying fully.\n",
            " approach a. the to. fit and one the\n",
            "rank 0 sample 2: Hello, I'm a language model,.. part partings students approachday,org.,\n",
            " a a,,.,,,,. position\n",
            "rank 0 sample 3: Hello, I'm a language model, theics spread,,,. the the out,, approachorg an the ideal in forward. fully the the position\n",
            "step 120 | loss: 8.718273162841797 | lr: 2.5385e-04 | norm: 14.7126 | dt=24213.08ms | 21653.09 tokens/sec\n",
            "step 121 | loss: 8.75292682647705 | lr: 2.5594e-04 | norm: 16.7693 | dt=23986.11ms | 21857.98 tokens/sec\n",
            "step 122 | loss: 8.75416088104248 | lr: 2.5804e-04 | norm: 17.1120 | dt=23980.75ms | 21862.87 tokens/sec\n",
            "step 123 | loss: 8.742436408996582 | lr: 2.6014e-04 | norm: 12.9581 | dt=23990.24ms | 21854.22 tokens/sec\n",
            "step 124 | loss: 8.778491020202637 | lr: 2.6224e-04 | norm: 9.5407 | dt=23939.25ms | 21900.77 tokens/sec\n",
            "tokens: tensor([[15496,    11,   314,  1101,   257,  3303,  2746,    11,    13,    13,\n",
            "           873,    13,    11,   355,   329,    69,  3748,  3748,    13,  4197,\n",
            "            11,  1577,   198,   329,    13,    11,  3970,   257,   262,    11,\n",
            "            13,   329],\n",
            "        [15496,    11,   314,  1101,   257,  3303,  2746,    11,    11,  4574,\n",
            "          3748,    13,   262,    13,   290,   340,    13,   262, 15964, 11841,\n",
            "            11,   329, 15964,   286,    11,   262,   379,    11,  3011,   290,\n",
            "            13,    13],\n",
            "        [15496,    11,   314,  1101,   257,  3303,  2746,    11,    11,    13,\n",
            "           658,   290,  1912,  7306,  3748,  1249,    13,  6842,    11,    13,\n",
            "           873,   286,    13,    13,    13,    11,    11,    13,    13,    13,\n",
            "            11,    11],\n",
            "        [15496,    11,   314,  1101,   257,  3303,  2746,    11,    11,  4574,\n",
            "            13,   290,    13,    13,    11,   262,   262,  1884,    13,    13,\n",
            "            13,    11,    13,   262, 13020,   257,  7306,    11,   379,    13,\n",
            "           262,   281]], device='cuda:0')\n",
            "rank 0 sample 0: Hello, I'm a language model,..ics., as forf unique unique. fit, give\n",
            " for.,ica a the,. for\n",
            "rank 0 sample 1: Hello, I'm a language model,, push unique. the. and it. the measuring dirty, for measuring of, the at, gets and..\n",
            "rank 0 sample 2: Hello, I'm a language model,,.ents and based ideal unique allow. bear,.ics of...,,...,,\n",
            "rank 0 sample 3: Hello, I'm a language model,, push. and.., the the likely...,. the grain a ideal, at. the an\n",
            "step 125 | loss: 8.784067153930664 | lr: 2.6434e-04 | norm: 8.4127 | dt=24122.29ms | 21734.58 tokens/sec\n",
            "step 126 | loss: 8.81511402130127 | lr: 2.6643e-04 | norm: 7.1118 | dt=23788.19ms | 22039.85 tokens/sec\n",
            "step 127 | loss: 8.655058860778809 | lr: 2.6853e-04 | norm: 6.9160 | dt=23839.19ms | 21992.69 tokens/sec\n",
            "step 128 | loss: 8.629759788513184 | lr: 2.7063e-04 | norm: 7.7418 | dt=23950.28ms | 21890.68 tokens/sec\n",
            "step 129 | loss: 8.587257385253906 | lr: 2.7273e-04 | norm: 8.8803 | dt=23911.69ms | 21926.01 tokens/sec\n",
            "tokens: tensor([[15496,    11,   314,  1101,   257,  3303,  2746,    11, 10087,   262,\n",
            "           318,   262,    13,   284,   287,   464,  2312,  1900,   329,  1363,\n",
            "           290, 10224,  3607,   198,   262,   286,  3607,   286,    11,   329,\n",
            "           262,   287],\n",
            "        [15496,    11,   314,  1101,   257,  3303,  2746,    11,   636,   540,\n",
            "          3607,   262,    11,   262,   290,  2252,   262,    11,  2067,  4958,\n",
            "            13,   198,  2312,   286,    13,    11,   287,    13, 10224,   290,\n",
            "           414,   286],\n",
            "        [15496,    11,   314,  1101,   257,  3303,  2746,    11,    13,   262,\n",
            "         50256,   290,  1390,    12,  2312,   287,   262,  2398,   379,   262,\n",
            "           257,   286,   286,   262,   257,    11,    11,   262,   262,   262,\n",
            "            13,   636],\n",
            "        [15496,    11,   314,  1101,   257,  3303,  2746,    11,   287,  1900,\n",
            "           884,   286,   262,   262,    13,    11,    11,  2726,   262,   262,\n",
            "          4197,  2398,   287,    11,  6306,   329,    12,  2252,  1900,    11,\n",
            "            11,   540]], device='cuda:0')\n",
            "rank 0 sample 0: Hello, I'm a language model, birds the is the. to inThe These known for home and conventional gives\n",
            " the of gives of, for the in\n",
            "rank 0 sample 1: Hello, I'm a language model, partable gives the, the and further the, started master.\n",
            " These of., in. conventional andity of\n",
            "rank 0 sample 2: Hello, I'm a language model,. the<|endoftext|> and including- These in theorg at the a of of the a,, the the the. part\n",
            "rank 0 sample 3: Hello, I'm a language model, in known such of the the.,, serious the the fitorg in, experiment for- further known,,able\n",
            "step 130 | loss: 8.65168571472168 | lr: 2.7483e-04 | norm: 11.2029 | dt=24048.81ms | 21801.00 tokens/sec\n",
            "step 131 | loss: 8.70207405090332 | lr: 2.7692e-04 | norm: 12.3144 | dt=23811.17ms | 22018.57 tokens/sec\n",
            "step 132 | loss: 8.731101036071777 | lr: 2.7902e-04 | norm: 10.3473 | dt=23818.46ms | 22011.84 tokens/sec\n",
            "step 133 | loss: 8.700885772705078 | lr: 2.8112e-04 | norm: 7.4066 | dt=23825.16ms | 22005.64 tokens/sec\n",
            "step 134 | loss: 8.6525239944458 | lr: 2.8322e-04 | norm: 5.6339 | dt=23794.01ms | 22034.45 tokens/sec\n",
            "tokens: tensor([[15496,    11,   314,  1101,   257,  3303,  2746,    11,    13,    13,\n",
            "          4197,    13,   262,    11,   329,    12,  1200,  1262,    13,   262,\n",
            "           262,  3608,  1200,   329,    13,   262,   308,   287,    11,   262,\n",
            "            13,    11],\n",
            "        [15496,    11,   314,  1101,   257,  3303,  2746,    11,    11,  1262,\n",
            "            13,    13,    11,    13,   262,   530,    13,    11,  1675,  1263,\n",
            "           262,    13, 10224,   286,   262,    11,  2319,   262,  3608,    11,\n",
            "            11,    11],\n",
            "        [15496,    11,   314,  1101,   257,  3303,  2746,    11,   262,    13,\n",
            "          7306,    11,   308,   318,   262,    11,    13,  7176,   262,   262,\n",
            "          2282,   286,    13,    13,    13,    11,    11,    13,    13,    13,\n",
            "           262,   262],\n",
            "        [15496,    11,   314,  1101,   257,  3303,  2746,    11,    11,  1262,\n",
            "            13,    13,    13,    13,   262,    11,    11,   530,    13,    13,\n",
            "            13,   262,    13,    11, 50256,   287,   318,   262,  5693,    11,\n",
            "            11,  1262]], device='cuda:0')\n",
            "rank 0 sample 0: Hello, I'm a language model,.. fit. the, for- child using. the the cool child for. the g in, the.,\n",
            "rank 0 sample 1: Hello, I'm a language model,, using..,. the one., To big the. conventional of the, 40 the cool,,,\n",
            "rank 0 sample 2: Hello, I'm a language model, the. ideal, g is the,. hopes the the saying of...,,... the the\n",
            "rank 0 sample 3: Hello, I'm a language model,, using.... the,, one... the.,<|endoftext|> in is the Foundation,, using\n",
            "step 135 | loss: 8.564154624938965 | lr: 2.8531e-04 | norm: 5.3134 | dt=24003.46ms | 21842.19 tokens/sec\n",
            "step 136 | loss: 8.547508239746094 | lr: 2.8741e-04 | norm: 2.7325 | dt=23672.81ms | 22147.26 tokens/sec\n",
            "step 137 | loss: 8.49372673034668 | lr: 2.8951e-04 | norm: 2.0710 | dt=23544.35ms | 22268.10 tokens/sec\n",
            "step 138 | loss: 8.473000526428223 | lr: 2.9161e-04 | norm: 2.5509 | dt=23393.48ms | 22411.71 tokens/sec\n",
            "step 139 | loss: 8.53925609588623 | lr: 2.9371e-04 | norm: 2.5620 | dt=23308.54ms | 22493.38 tokens/sec\n",
            "tokens: tensor([[15496,    11,   314,  1101,   257,  3303,  2746,    11,  7565,    11,\n",
            "           287,    11,   262,  7176,   257,  7306,  1675,  1895,   329,  2221,\n",
            "           290,   373,  6027,   257,    11,   286,   530,   329,    13,   329,\n",
            "            11,   257],\n",
            "        [15496,    11,   314,  1101,   257,  3303,  2746,    11,   357,  3011,\n",
            "          6693,    11,    13,    11,   290,  2126,    11,    13,   530,   281,\n",
            "           262,   257,  1103,   286,   262,    13,   198,   262,   373,   290,\n",
            "          2221,   286],\n",
            "        [15496,    11,   314,  1101,   257,  3303,  2746,    11,   262,    11,\n",
            "          1180,   290,   345,   884,  1103,  6027,    11,   318,   654,    11,\n",
            "            12,   286,   286,    11,    12,   262,    13,    11,   587,    11,\n",
            "           262,   357],\n",
            "        [15496,    11,   314,  1101,   257,  3303,  2746,    11,   198,  1895,\n",
            "           636,   286,    11,   290,   262,    13,    13,   636,    11,    11,\n",
            "          6693,   318,   198,    13,   991,   329,   884,   262,  3613,    13,\n",
            "            13,  1895]], device='cuda:0')\n",
            "rank 0 sample 0: Hello, I'm a language model, vary, in, the hopes a ideal To access for begin and was planned a, of one for. for, a\n",
            "rank 0 sample 1: Hello, I'm a language model, ( gets discussed,., and idea,. one an the a real of the.\n",
            " the was and begin of\n",
            "rank 0 sample 2: Hello, I'm a language model, the, different and you such real planned, isings,- of of,- the., been, the (\n",
            "rank 0 sample 3: Hello, I'm a language model,\n",
            " access part of, and the.. part,, discussed is\n",
            ". still for such the save.. access\n",
            "step 140 | loss: 8.496498107910156 | lr: 2.9580e-04 | norm: 2.6048 | dt=23583.93ms | 22230.73 tokens/sec\n",
            "step 141 | loss: 8.52000617980957 | lr: 2.9790e-04 | norm: 2.5928 | dt=23317.27ms | 22484.96 tokens/sec\n",
            "step 142 | loss: 8.476326942443848 | lr: 3.0000e-04 | norm: 2.6242 | dt=23325.95ms | 22476.60 tokens/sec\n",
            "step 143 | loss: 8.50247573852539 | lr: 3.0210e-04 | norm: 2.6079 | dt=23334.22ms | 22468.63 tokens/sec\n",
            "step 144 | loss: 8.572676658630371 | lr: 3.0420e-04 | norm: 2.5917 | dt=23311.16ms | 22490.86 tokens/sec\n",
            "tokens: tensor([[15496,    11,   314,  1101,   257,  3303,  2746,    11,  3094,    11,\n",
            "           287,    11,   262,   284,   198,   884,   654,  5693,   329,  6693,\n",
            "            13,  3613,   654,   198,    11,   286,  3011,   329,   290,   329,\n",
            "            11,   198],\n",
            "        [15496,    11,   314,  1101,   257,  3303,  2746,    11,   355,   355,\n",
            "          4203,    11,   290,   357,    13,   317,    11,   290,   475,  1895,\n",
            "           262,   198,  3011,   286,   262,   290,   257,   262,  3613,    13,\n",
            "          6693,   286],\n",
            "        [15496,    11,   314,  1101,   257,  3303,  2746,    11,   262,    11,\n",
            "           991,    13,   345,   373,   475,   257,    11,  7306,   345,    11,\n",
            "            12,   286,   286,    11,    12,   290,   290,    11,  1110,    11,\n",
            "           262,   355],\n",
            "        [15496,    11,   314,  1101,   257,  3303,  2746,    11,   257,  5693,\n",
            "           790,   286,    11,    13,   262,   373,   290,  3068,    11,   257,\n",
            "          1675,  7306,   257,   290,   317,   329,   373,  3094,   357,   290,\n",
            "           290,  5693]], device='cuda:0')\n",
            "rank 0 sample 0: Hello, I'm a language model, wide, in, the to\n",
            " suchings Foundation for discussed. saveings\n",
            ", of gets for and for,\n",
            "\n",
            "rank 0 sample 1: Hello, I'm a language model, as as feeling, and (. A, and but access the\n",
            " gets of the and a the save. discussed of\n",
            "rank 0 sample 2: Hello, I'm a language model, the, still. you was but a, ideal you,- of of,- and and, day, the as\n",
            "rank 0 sample 3: Hello, I'm a language model, a Foundation every of,. the was and mention, a To ideal a and A for was wide ( and and Foundation\n",
            "step 145 | loss: 8.547171592712402 | lr: 3.0629e-04 | norm: 2.6078 | dt=23542.76ms | 22269.61 tokens/sec\n",
            "step 146 | loss: 8.54669189453125 | lr: 3.0839e-04 | norm: 2.5909 | dt=23359.47ms | 22444.34 tokens/sec\n",
            "step 147 | loss: 8.557087898254395 | lr: 3.1049e-04 | norm: 2.6056 | dt=23306.39ms | 22495.46 tokens/sec\n",
            "step 148 | loss: 8.521324157714844 | lr: 3.1259e-04 | norm: 2.5912 | dt=23324.05ms | 22478.43 tokens/sec\n",
            "step 149 | loss: 8.54511833190918 | lr: 3.1469e-04 | norm: 2.5925 | dt=23282.83ms | 22518.22 tokens/sec\n",
            "validation loss: 8.5411\n",
            "helloswag accuracy: 2591/10042 0.2580\n",
            "tokens: tensor([[15496,    11,   314,  1101,   257,  3303,  2746,    11,  3011,    11,\n",
            "           287,    11,   290,   884,   198,   284,  1180,   607,   329,  1022,\n",
            "            13,   852,   281,   198,    11,   286,   654,   329,   262,   329,\n",
            "            11,   198],\n",
            "        [15496,    11,   314,  1101,   257,  3303,  2746,    11,   991,  6027,\n",
            "           317,    11,   262,   355,    13,  4133,    11,   262,   654,   355,\n",
            "           290,   198,   317,   286,   290,   262,   257,   290,   852,    13,\n",
            "          1022,   286],\n",
            "        [15496,    11,   314,  1101,   257,  3303,  2746,    11,   290,    11,\n",
            "           414,   355,  4203,  7306,   317,   257,    11,   373,   281,    11,\n",
            "            12,   286,   286,    11,    12,   262,   262,    11,   530,    11,\n",
            "           290,   991],\n",
            "        [15496,    11,   314,  1101,   257,  3303,  2746,    11,   257,   607,\n",
            "          1022,   286,    11,   329,   290,  7306,   262,  5693,   329,   257,\n",
            "          3307,   373,   257,   262,  1255,   329,  7306,  5693,  1895,   790,\n",
            "           262,   607]], device='cuda:0')\n",
            "rank 0 sample 0: Hello, I'm a language model, gets, in, and such\n",
            " to different her for between. being an\n",
            ", ofings for the for,\n",
            "\n",
            "rank 0 sample 1: Hello, I'm a language model, still planned A, the as. resources, theings as and\n",
            " A of and the a and being. between of\n",
            "rank 0 sample 2: Hello, I'm a language model, and,ity as feeling ideal A a, was an,- of of,- the the, one, and still\n",
            "rank 0 sample 3: Hello, I'm a language model, a her between of, for and ideal the Foundation for a details was a the result for ideal Foundation access every the her\n",
            "step 150 | loss: 8.589248657226562 | lr: 3.1678e-04 | norm: 2.5541 | dt=130901.11ms | 4005.22 tokens/sec\n",
            "step 151 | loss: 8.486310958862305 | lr: 3.1888e-04 | norm: 2.6310 | dt=23331.60ms | 22471.16 tokens/sec\n",
            "step 152 | loss: 8.499246597290039 | lr: 3.2098e-04 | norm: 2.6511 | dt=23324.45ms | 22478.04 tokens/sec\n",
            "step 153 | loss: 8.504438400268555 | lr: 3.2308e-04 | norm: 2.5968 | dt=23328.17ms | 22474.46 tokens/sec\n",
            "step 154 | loss: 8.566160202026367 | lr: 3.2517e-04 | norm: 2.6502 | dt=23307.10ms | 22494.78 tokens/sec\n",
            "tokens: tensor([[15496,    11,   314,  1101,   257,  3303,  2746,    11,  3011,    11,\n",
            "           287,    11,   290,   884,   198,   284,  1180,   414,   329,  4133,\n",
            "           286,   357,  2221,   198,    11,    13,   317,   329,   262,   329,\n",
            "            11,   198],\n",
            "        [15496,    11,   314,  1101,   257,  3303,  2746,    11,   607,   414,\n",
            "          1255,   287,   262,  1895,   286,  1022,    11,   262,  7176,  1895,\n",
            "           290,   198,  1255,    13,   290,   262,   257,   290,   357,   286,\n",
            "          4133,    13],\n",
            "        [15496,    11,   314,  1101,   257,  3303,  2746,    11,   290,    11,\n",
            "          4203,  1895,  2221,  7306,   790,   257,    11,   373,  2221,    11,\n",
            "            12,    13,   286,    11,    12,  3307,   262,    11,   530,    11,\n",
            "           290,   607],\n",
            "        [15496,    11,   314,  1101,   257,  3303,  2746,    11,   257,   414,\n",
            "          3068,    13,    11,   329,   290,  7306,   262,  3068,   329,   257,\n",
            "          3307,   373,   257,   262,    25,   329,  7306,  4104,   475,  1675,\n",
            "           262,   414]], device='cuda:0')\n",
            "rank 0 sample 0: Hello, I'm a language model, gets, in, and such\n",
            " to differentity for resources of ( begin\n",
            ",. A for the for,\n",
            "\n",
            "rank 0 sample 1: Hello, I'm a language model, herity result in the access of between, the hopes access and\n",
            " result. and the a and ( of resources.\n",
            "rank 0 sample 2: Hello, I'm a language model, and, feeling access begin ideal every a, was begin,-. of,- details the, one, and her\n",
            "rank 0 sample 3: Hello, I'm a language model, aity mention., for and ideal the mention for a details was a the: for ideal spread but To theity\n",
            "step 155 | loss: 8.498611450195312 | lr: 3.2727e-04 | norm: 2.6382 | dt=23554.82ms | 22258.20 tokens/sec\n",
            "step 156 | loss: 8.47183895111084 | lr: 3.2937e-04 | norm: 2.6709 | dt=23317.04ms | 22485.19 tokens/sec\n",
            "step 157 | loss: 8.468530654907227 | lr: 3.3147e-04 | norm: 2.6593 | dt=23329.59ms | 22473.09 tokens/sec\n",
            "step 158 | loss: 8.474920272827148 | lr: 3.3357e-04 | norm: 2.6396 | dt=23310.15ms | 22491.83 tokens/sec\n",
            "step 159 | loss: 8.50217056274414 | lr: 3.3566e-04 | norm: 2.6537 | dt=23331.62ms | 22471.13 tokens/sec\n",
            "tokens: tensor([[15496,    11,   314,  1101,   257,  3303,  2746,    11,  1103,    11,\n",
            "           287,    11,   290,   884,   198,   284,   790,   414,   329,  3307,\n",
            "           286,   355,  2221,   198,    11,    13,  6027,   329,   262,   329,\n",
            "            11,   198],\n",
            "        [15496,    11,   314,  1101,   257,  3303,  2746,    11,  3094,   414,\n",
            "           317,   287,   262,  1895,   286,  4133,    11,   262,  6027,  1895,\n",
            "           290,   198,   317,    13,   290,   262,   257,   290,   355,   286,\n",
            "          1103,    13],\n",
            "        [15496,    11,   314,  1101,   257,  3303,  2746,    11,   290,    11,\n",
            "           345,  1895,  1180,  7306,   317,   257,    11,   373,  1180,    11,\n",
            "            12,    13,    13,    11,    12,  1022,   262,    11,  3011,    11,\n",
            "           290,  3094],\n",
            "        [15496,    11,   314,  1101,   257,  3303,  2746,    11,   257,   414,\n",
            "          1813,    13,    11,   329,   290,  7306,   262,  1813,   329,   257,\n",
            "            25,   373,   257,   262,   250,   329,  7306,  1813,   475,  1022,\n",
            "           262,   414]], device='cuda:0')\n",
            "rank 0 sample 0: Hello, I'm a language model, real, in, and such\n",
            " to everyity for details of as begin\n",
            ",. planned for the for,\n",
            "\n",
            "rank 0 sample 1: Hello, I'm a language model, wideity A in the access of resources, the planned access and\n",
            " A. and the a and as of real.\n",
            "rank 0 sample 2: Hello, I'm a language model, and, you access different ideal A a, was different,-..,- between the, gets, and wide\n",
            "rank 0 sample 3: Hello, I'm a language model, aity given., for and ideal the given for a: was a the� for ideal given but between theity\n",
            "step 160 | loss: 8.4502534866333 | lr: 3.3776e-04 | norm: 2.6543 | dt=23537.89ms | 22274.22 tokens/sec\n",
            "step 161 | loss: 8.43851375579834 | lr: 3.3986e-04 | norm: 2.6720 | dt=23337.62ms | 22465.36 tokens/sec\n",
            "step 162 | loss: 8.441993713378906 | lr: 3.4196e-04 | norm: 2.6822 | dt=23225.65ms | 22573.67 tokens/sec\n",
            "step 163 | loss: 8.507728576660156 | lr: 3.4406e-04 | norm: 2.6754 | dt=23333.63ms | 22469.20 tokens/sec\n",
            "step 164 | loss: 8.457442283630371 | lr: 3.4615e-04 | norm: 2.6964 | dt=23365.07ms | 22438.97 tokens/sec\n",
            "tokens: tensor([[15496,    11,   314,  1101,   257,  3303,  2746,    11,  1813,    11,\n",
            "           287,    11,   290,   884,   198,   284,  2221,  4203,   329,  4104,\n",
            "           286,  3613,  3094,   198,    11,    13,   250,   329,   262,   329,\n",
            "            11,   198],\n",
            "        [15496,    11,   314,  1101,   257,  3303,  2746,    11,   414,  4203,\n",
            "         10975,   287,   262,   357,   286,    25,    11,   262,   250,   357,\n",
            "           290,   198, 10975,    13,   290,   262,   257,   290,  1895,   286,\n",
            "          4104,    13],\n",
            "        [15496,    11,   314,  1101,   257,  3303,  2746,    11,   290,    11,\n",
            "           281,   357,  3094,  7306, 10975,   257,    11,   373,  3094,   290,\n",
            "            12,    13,    13,    11,    12,  1022,   262,    11,   845,    11,\n",
            "           290,   414],\n",
            "        [15496,    11,   314,  1101,   257,  3303,  2746,    11,   257,  4203,\n",
            "          1103,    13,    11,   329,   290,  7306,   262,  1813,   329,   257,\n",
            "          1022,   373,   257,   262,  6027,   329,  7306,  1813,   852,   317,\n",
            "           262,  4203]], device='cuda:0')\n",
            "rank 0 sample 0: Hello, I'm a language model, given, in, and such\n",
            " to begin feeling for spread of save wide\n",
            ",.� for the for,\n",
            "\n",
            "rank 0 sample 1: Hello, I'm a language model,ity feeling affects in the ( of:, the� ( and\n",
            " affects. and the a and access of spread.\n",
            "rank 0 sample 2: Hello, I'm a language model, and, an ( wide ideal affects a, was wide and-..,- between the, very, andity\n",
            "rank 0 sample 3: Hello, I'm a language model, a feeling real., for and ideal the given for a between was a the planned for ideal given being A the feeling\n",
            "step 165 | loss: 8.45382022857666 | lr: 3.4825e-04 | norm: 2.7180 | dt=23552.21ms | 22260.67 tokens/sec\n",
            "step 166 | loss: 8.48756217956543 | lr: 3.5035e-04 | norm: 2.6605 | dt=23310.17ms | 22491.81 tokens/sec\n",
            "step 167 | loss: 8.47430419921875 | lr: 3.5245e-04 | norm: 2.7164 | dt=23320.30ms | 22482.05 tokens/sec\n",
            "step 168 | loss: 8.51976203918457 | lr: 3.5455e-04 | norm: 2.6947 | dt=23325.75ms | 22476.79 tokens/sec\n",
            "step 169 | loss: 8.473596572875977 | lr: 3.5664e-04 | norm: 2.6972 | dt=23300.52ms | 22501.13 tokens/sec\n",
            "tokens: tensor([[15496,    11,   314,  1101,   257,  3303,  2746,    11,    25,    11,\n",
            "           287,    11,   290,   884,   198,   284,  3094,   357,   329,    25,\n",
            "           286,  7306,  1255,   198,    11,    13,  2221,   329,   262,   329,\n",
            "            11,   198],\n",
            "        [15496,    11,   314,  1101,   257,  3303,  2746,    11,  1180,   357,\n",
            "          1675,   287,   262,  4203,   286,  1752,    11,   262,  2221,   991,\n",
            "           290,   198,  1675,    13,   290,   262,   257,   290,  7306,   286,\n",
            "          4133,    13],\n",
            "        [15496,    11,   314,  1101,   257,  3303,  2746,    11,   290,    11,\n",
            "           281,  4203,  1255,  1895,  1675,   257,    11,   373,  1255,   290,\n",
            "            12,    13,    13,    11,    12,   607,   262,    11,   845,    11,\n",
            "           290,   414],\n",
            "        [15496,    11,   314,  1101,   257,  3303,  2746,    11,   257,   357,\n",
            "            25,    13,    11,   329,   290,  1895,   262,   464,   329,   257,\n",
            "          4104,   373,   257,   262,  2198,   329,  1895,  4133,   475,  1022,\n",
            "           262,   357]], device='cuda:0')\n",
            "rank 0 sample 0: Hello, I'm a language model,:, in, and such\n",
            " to wide ( for: of ideal result\n",
            ",. begin for the for,\n",
            "\n",
            "rank 0 sample 1: Hello, I'm a language model, different ( To in the feeling of once, the begin still and\n",
            " To. and the a and ideal of resources.\n",
            "rank 0 sample 2: Hello, I'm a language model, and, an feeling result access To a, was result and-..,- her the, very, andity\n",
            "rank 0 sample 3: Hello, I'm a language model, a (:., for and access theThe for a spread was a the check for access resources but between the (\n",
            "step 170 | loss: 8.432537078857422 | lr: 3.5874e-04 | norm: 2.7316 | dt=23549.60ms | 22263.14 tokens/sec\n",
            "step 171 | loss: 8.483551025390625 | lr: 3.6084e-04 | norm: 2.7210 | dt=23415.67ms | 22390.48 tokens/sec\n",
            "step 172 | loss: 8.51976203918457 | lr: 3.6294e-04 | norm: 2.7282 | dt=23314.62ms | 22487.53 tokens/sec\n",
            "step 173 | loss: 8.469964981079102 | lr: 3.6503e-04 | norm: 2.7174 | dt=23258.49ms | 22541.79 tokens/sec\n",
            "step 174 | loss: 8.545690536499023 | lr: 3.6713e-04 | norm: 2.7464 | dt=23315.98ms | 22486.21 tokens/sec\n",
            "tokens: tensor([[15496,    11,   314,  1101,   257,  3303,  2746,    11,  4133,    11,\n",
            "           287,    11,   290,   884,   198,   284,   414,   991,   329,   464,\n",
            "           286,   373, 10975,   198,    11,    13,  1675,   329,   262,   329,\n",
            "            11,   198],\n",
            "        [15496,    11,   314,  1101,   257,  3303,  2746,    11,   357,   991,\n",
            "          2221,   287,   262,   475,   286,  1752,    11,   262,  1675,   475,\n",
            "           290,   198,  2221,    13,   290,   262,   257,   290,   373,   286,\n",
            "           464,    13],\n",
            "        [15496,    11,   314,  1101,   257,  3303,  2746,    11,   290,    11,\n",
            "           281,   345, 10975,   355,  2221,   257,    11,  1895, 10975,   290,\n",
            "            12,    13,    13,    11,    12,  2198,   262,    11,   845,    11,\n",
            "           290,  1180],\n",
            "        [15496,    11,   314,  1101,   257,  3303,  2746,    11,   257,   991,\n",
            "            25,   198,    11,   329,   290,   355,   262,  4133,   329,   257,\n",
            "          2198,  1895,   257,   262,  1022,   329,   355,   503,   852,  6032,\n",
            "           262,   991]], device='cuda:0')\n",
            "rank 0 sample 0: Hello, I'm a language model, resources, in, and such\n",
            " toity still forThe of was affects\n",
            ",. To for the for,\n",
            "\n",
            "rank 0 sample 1: Hello, I'm a language model, ( still begin in the but of once, the To but and\n",
            " begin. and the a and was ofThe.\n",
            "rank 0 sample 2: Hello, I'm a language model, and, an you affects as begin a, access affects and-..,- check the, very, and different\n",
            "rank 0 sample 3: Hello, I'm a language model, a still:\n",
            ", for and as the resources for a check access a the between for as out being typically the still\n",
            "step 175 | loss: 8.613146781921387 | lr: 3.6923e-04 | norm: 2.7758 | dt=23543.09ms | 22269.30 tokens/sec\n",
            "step 176 | loss: 8.613874435424805 | lr: 3.7133e-04 | norm: 2.7563 | dt=23353.51ms | 22450.07 tokens/sec\n",
            "step 177 | loss: 8.608841896057129 | lr: 3.7343e-04 | norm: 2.7908 | dt=23318.69ms | 22483.59 tokens/sec\n",
            "step 178 | loss: 8.657044410705566 | lr: 3.7552e-04 | norm: 2.7998 | dt=23327.90ms | 22474.72 tokens/sec\n",
            "step 179 | loss: 8.698385238647461 | lr: 3.7762e-04 | norm: 2.7808 | dt=23341.46ms | 22461.67 tokens/sec\n",
            "tokens: tensor([[15496,    11,   314,  1101,   257,  3303,  2746,    11,   503,    11,\n",
            "           287,    11,   290,   884,    13,   284, 10975,   991,   329,  1752,\n",
            "           286,  4203,   250,    13,    11,   198,  4104,   329,   262,   329,\n",
            "            11,    13],\n",
            "        [15496,    11,   314,  1101,   257,  3303,  2746,    11,  1180,   991,\n",
            "           414,   287,   262,   475,   286,    25,    11,   262,  4104,   475,\n",
            "           290,    13,   414,   198,   290,   262,   257,   290,  4203,   286,\n",
            "          1752,   198],\n",
            "        [15496,    11,   314,  1101,   257,  3303,  2746,    11,   290,    11,\n",
            "          1255,   475,  1675,   355,  4104,   257,    11,  1895,  3094,   290,\n",
            "            12,   198,   286,    11,    12,   290,   262,    11,   319,    11,\n",
            "           290,  1180],\n",
            "        [15496,    11,   314,  1101,   257,  3303,  2746,    11,   257,   991,\n",
            "          6032,   198,    11,   329,   290,   355,   262,   503,   329,   257,\n",
            "          1022,  1895,   257,   262,  1103,   329,   355,  6032,  3613,  2198,\n",
            "           262,   991]], device='cuda:0')\n",
            "rank 0 sample 0: Hello, I'm a language model, out, in, and such. to affects still for once of feeling�.,\n",
            " spread for the for,.\n",
            "rank 0 sample 1: Hello, I'm a language model, different stillity in the but of:, the spread but and.ity\n",
            " and the a and feeling of once\n",
            "\n",
            "rank 0 sample 2: Hello, I'm a language model, and, result but To as spread a, access wide and-\n",
            " of,- and the, on, and different\n",
            "rank 0 sample 3: Hello, I'm a language model, a still typically\n",
            ", for and as the out for a between access a the real for as typically save check the still\n",
            "step 180 | loss: 8.649123191833496 | lr: 3.7972e-04 | norm: 2.8236 | dt=23546.02ms | 22266.53 tokens/sec\n",
            "step 181 | loss: 8.624982833862305 | lr: 3.8182e-04 | norm: 2.8469 | dt=23324.51ms | 22477.98 tokens/sec\n",
            "step 182 | loss: 8.65410327911377 | lr: 3.8392e-04 | norm: 2.8101 | dt=23343.43ms | 22459.77 tokens/sec\n",
            "step 183 | loss: 8.6063871383667 | lr: 3.8601e-04 | norm: 2.8536 | dt=23323.39ms | 22479.06 tokens/sec\n",
            "step 184 | loss: 8.802987098693848 | lr: 3.8811e-04 | norm: 2.8047 | dt=23333.88ms | 22468.96 tokens/sec\n",
            "tokens: tensor([[15496,    11,   314,  1101,   257,  3303,  2746,    11,  1752,    11,\n",
            "           287,    11,   290,   884,    13,   284,  1675,  1255,   329,   530,\n",
            "           198,   852,  1675,    13,    11,   286,   414,   329,   262,   329,\n",
            "            11,    13],\n",
            "        [15496,    11,   314,  1101,   257,  3303,  2746,    11,  7306,  7306,\n",
            "            25,   287,   262,  3613,   286,   530,    11,   262,    25,  3613,\n",
            "           290,    13,   414,   286,   290,   262,   257,   290,   852,   198,\n",
            "           503,   286],\n",
            "        [15496,    11,   314,  1101,   257,  3303,  2746,    11,   290,    11,\n",
            "           345,  3613,  1675,   373,    25,   257,    11,   355,  3094,    11,\n",
            "            12,   286,   198,    11,    12,   262,   262,    11,  4133,    11,\n",
            "           290,  7306],\n",
            "        [15496,    11,   314,  1101,   257,  3303,  2746,    11,   257,  1255,\n",
            "          1103,   198,    11,   329,   290,   373,   262,  6817,   329,   257,\n",
            "          1022,   355,   257,   262,   250,   329,   373,  1752,   991, 10975,\n",
            "           262,   281]], device='cuda:0')\n",
            "rank 0 sample 0: Hello, I'm a language model, once, in, and such. to To result for one\n",
            " being To., ofity for the for,.\n",
            "rank 0 sample 1: Hello, I'm a language model, ideal ideal: in the save of one, the: save and.ity of and the a and being\n",
            " out of\n",
            "rank 0 sample 2: Hello, I'm a language model, and, you save To was: a, as wide,- of\n",
            ",- the the, resources, and ideal\n",
            "rank 0 sample 3: Hello, I'm a language model, a result real\n",
            ", for and was the importance for a between as a the� for was once still affects the an\n",
            "step 185 | loss: 8.676957130432129 | lr: 3.9021e-04 | norm: 2.8599 | dt=23560.89ms | 22252.47 tokens/sec\n",
            "step 186 | loss: 8.587234497070312 | lr: 3.9231e-04 | norm: 2.8387 | dt=23223.78ms | 22575.48 tokens/sec\n",
            "step 187 | loss: 8.68022632598877 | lr: 3.9441e-04 | norm: 2.7140 | dt=23316.90ms | 22485.32 tokens/sec\n",
            "step 188 | loss: 8.697580337524414 | lr: 3.9650e-04 | norm: 2.5996 | dt=23351.35ms | 22452.15 tokens/sec\n",
            "step 189 | loss: 8.680617332458496 | lr: 3.9860e-04 | norm: 2.6082 | dt=23306.23ms | 22495.62 tokens/sec\n",
            "tokens: tensor([[15496,    11,   314,  1101,   257,  3303,  2746,    11,  6817,    11,\n",
            "           287,    11,   290,   884,    13,   284,   790,  3613,   329,   317,\n",
            "           198,   852,  7306,    13,    11,   286,  2221,   329,   262,   329,\n",
            "            11,    13],\n",
            "        [15496,    11,   314,  1101,   257,  3303,  2746,    11,  4104,  3613,\n",
            "           345,   287,   262,   281,   198,   319,    11,   262,  2221,   281,\n",
            "           290,    13,  1022,   286,   290,   262,   257,   290,   852,   198,\n",
            "           317,   286],\n",
            "        [15496,    11,   314,  1101,   257,  3303,  2746,    11,   290,    11,\n",
            "            25,   281,  7306,   355,  1022,   257,    11,   373,  7306,   290,\n",
            "            12,   286,   198,    11,    12,   262,   262,    11,   812,    11,\n",
            "           290,  3094],\n",
            "        [15496,    11,   314,  1101,   257,  3303,  2746,    11,   257,  3613,\n",
            "           317,   286,    11,   329,   290,   355,   262,  6817,   329,   257,\n",
            "           414,   373,   257,   262,   845,   329,   355,  1103,   991,   845,\n",
            "           262,  3613]], device='cuda:0')\n",
            "rank 0 sample 0: Hello, I'm a language model, importance, in, and such. to every save for A\n",
            " being ideal., of begin for the for,.\n",
            "rank 0 sample 1: Hello, I'm a language model, spread save you in the an\n",
            " on, the begin an and. between of and the a and being\n",
            " A of\n",
            "rank 0 sample 2: Hello, I'm a language model, and,: an ideal as between a, was ideal and- of\n",
            ",- the the, years, and wide\n",
            "rank 0 sample 3: Hello, I'm a language model, a save A of, for and as the importance for aity was a the very for as real still very the save\n",
            "step 190 | loss: 8.643614768981934 | lr: 4.0070e-04 | norm: 2.6559 | dt=23519.31ms | 22291.81 tokens/sec\n",
            "step 191 | loss: 8.706296920776367 | lr: 4.0280e-04 | norm: 2.8411 | dt=23322.19ms | 22480.22 tokens/sec\n",
            "step 192 | loss: 8.707411766052246 | lr: 4.0490e-04 | norm: 2.8869 | dt=23324.91ms | 22477.60 tokens/sec\n",
            "step 193 | loss: 8.632401466369629 | lr: 4.0699e-04 | norm: 2.8453 | dt=23342.13ms | 22461.01 tokens/sec\n",
            "step 194 | loss: 8.710797309875488 | lr: 4.0909e-04 | norm: 2.9003 | dt=23326.99ms | 22475.60 tokens/sec\n",
            "tokens: tensor([[15496,    11,   314,  1101,   257,  3303,  2746,    11,  1103,   290,\n",
            "           287,   290,    11,   884,    13,   284,   530,    25,   329,   317,\n",
            "           286,   852,   790,    13,   290,   198,  1022,   329,   262,   329,\n",
            "           290,    13],\n",
            "        [15496,    11,   314,  1101,   257,  3303,  2746,    11,  3613,    25,\n",
            "          2221,   287,   262,  1255,   286,  4203,   290,   262,  1022,  1255,\n",
            "            11,    13,   503,   198,    11,   262,   257,    11,   852,   286,\n",
            "           317,   198],\n",
            "        [15496,    11,   314,  1101,   257,  3303,  2746,    11,    11,   290,\n",
            "           464,  1255,  1180,   355,   503,   257,   290,   373,   790,    11,\n",
            "            12,   198,   286,   290,    12,   262,   262,   290,   788,   290,\n",
            "            11,  3613],\n",
            "        [15496,    11,   314,  1101,   257,  3303,  2746,    11,   257,    25,\n",
            "          7306,   198,   290,   329,    11,   355,   262,  1103,   329,   257,\n",
            "           414,   373,   257,   262,  1813,   329,   355,  1103,   281,   262,\n",
            "           262,    25]], device='cuda:0')\n",
            "rank 0 sample 0: Hello, I'm a language model, real and in and, such. to one: for A of being every. and\n",
            " between for the for and.\n",
            "rank 0 sample 1: Hello, I'm a language model, save: begin in the result of feeling and the between result,. out\n",
            ", the a, being of A\n",
            "\n",
            "rank 0 sample 2: Hello, I'm a language model,, andThe result different as out a and was every,-\n",
            " of and- the the and then and, save\n",
            "rank 0 sample 3: Hello, I'm a language model, a: ideal\n",
            " and for, as the real for aity was a the given for as real an the the:\n",
            "step 195 | loss: 8.642315864562988 | lr: 4.1119e-04 | norm: 2.8861 | dt=23565.86ms | 22247.78 tokens/sec\n",
            "step 196 | loss: 8.660778045654297 | lr: 4.1329e-04 | norm: 2.8834 | dt=23326.66ms | 22475.91 tokens/sec\n",
            "step 197 | loss: 8.779955863952637 | lr: 4.1538e-04 | norm: 2.8580 | dt=23309.63ms | 22492.33 tokens/sec\n",
            "step 198 | loss: 8.623907089233398 | lr: 4.1748e-04 | norm: 2.9296 | dt=23286.20ms | 22514.96 tokens/sec\n",
            "step 199 | loss: 8.71636962890625 | lr: 4.1958e-04 | norm: 2.9171 | dt=23185.99ms | 22612.28 tokens/sec\n",
            "validation loss: 8.8016\n",
            "helloswag accuracy: 2609/10042 0.2598\n",
            "tokens: tensor([[15496,    11,   314,  1101,   257,  3303,  2746,    11,   788,    11,\n",
            "           287,    11,   290,   884,    13,   284,  1895,   845,   329,   636,\n",
            "           286,   852,  3613,    13,    11,   198,  1022,   329,   262,   329,\n",
            "            11,    13],\n",
            "        [15496,    11,   314,  1101,   257,  3303,  2746,    11,   464,    25,\n",
            "          2221,   287,   262,  1255,   286,   317,    11,   262,  1022,  1255,\n",
            "           262,    13,  2221,   198,   290,   262,   257,   262,   852,   286,\n",
            "           636,   198],\n",
            "        [15496,    11,   314,  1101,   257,  3303,  2746,    11,   290,    11,\n",
            "           503,   286,  3613,   355,  1022,   257,    11,   373,  3613,   290,\n",
            "            12,   198,   198,    11,    12,   290,   262,    11,   345,    11,\n",
            "           290,   464],\n",
            "        [15496,    11,   314,  1101,   257,  3303,  2746,    11,   257,   845,\n",
            "          1103,   198,    11,   329,   262,   355,   262,   812,   329,   257,\n",
            "          4104,   373,   257,   262,  1752,   329,   355,   788,   281,   290,\n",
            "           262,   845]], device='cuda:0')\n",
            "rank 0 sample 0: Hello, I'm a language model, then, in, and such. to access very for part of being save.,\n",
            " between for the for,.\n",
            "rank 0 sample 1: Hello, I'm a language model,The: begin in the result of A, the between result the. begin\n",
            " and the a the being of part\n",
            "\n",
            "rank 0 sample 2: Hello, I'm a language model, and, out of save as between a, was save and-\n",
            "\n",
            ",- and the, you, andThe\n",
            "rank 0 sample 3: Hello, I'm a language model, a very real\n",
            ", for the as the years for a spread was a the once for as then an and the very\n",
            "step 200 | loss: 8.73262882232666 | lr: 4.2168e-04 | norm: 2.9336 | dt=130356.23ms | 4021.96 tokens/sec\n",
            "step 201 | loss: 8.72878360748291 | lr: 4.2378e-04 | norm: 2.9280 | dt=23402.58ms | 22403.00 tokens/sec\n",
            "step 202 | loss: 8.686149597167969 | lr: 4.2587e-04 | norm: 2.9439 | dt=23336.34ms | 22466.59 tokens/sec\n",
            "step 203 | loss: 8.722684860229492 | lr: 4.2797e-04 | norm: 2.9049 | dt=23263.46ms | 22536.97 tokens/sec\n",
            "step 204 | loss: 8.806175231933594 | lr: 4.3007e-04 | norm: 2.7592 | dt=23292.19ms | 22509.18 tokens/sec\n",
            "tokens: tensor([[15496,    11,   314,  1101,   257,  3303,  2746,    11,   812,    11,\n",
            "           287,    11,   262,   884,   198,   284,  1022,   790,   329,  1675,\n",
            "           286,   852,  1180,   198,    11,    13,  1752,   329,   290,   329,\n",
            "            11,   198],\n",
            "        [15496,    11,   314,  1101,   257,  3303,  2746,    11,   530,   790,\n",
            "          1895,   287,   290,  1255,   286,  4104,    11,   290,  1752,  1255,\n",
            "           262,   198,  1895,   198,   262,   290,   257,   262,   852,   286,\n",
            "          1675,   198],\n",
            "        [15496,    11,   314,  1101,   257,  3303,  2746,    11,   262,   262,\n",
            "          1813,   286,  1180,   355,  1895,   257,    11,   373,  1180,   262,\n",
            "            12,   198,   198,    11,    12,   290,   290,    11,  6817,    11,\n",
            "           262,   530],\n",
            "        [15496,    11,   314,  1101,   257,  3303,  2746,    11,   257,   790,\n",
            "           636,   198,    11,   329,   262,   355,   290,   812,   329,   257,\n",
            "          3613,   373,   257,   290,   414,   329,   355,   636,   281,   290,\n",
            "           290,   790]], device='cuda:0')\n",
            "rank 0 sample 0: Hello, I'm a language model, years, in, the such\n",
            " to between every for To of being different\n",
            ",. once for and for,\n",
            "\n",
            "rank 0 sample 1: Hello, I'm a language model, one every access in and result of spread, and once result the\n",
            " access\n",
            " the and a the being of To\n",
            "\n",
            "rank 0 sample 2: Hello, I'm a language model, the the given of different as access a, was different the-\n",
            "\n",
            ",- and and, importance, the one\n",
            "rank 0 sample 3: Hello, I'm a language model, a every part\n",
            ", for the as and years for a save was a andity for as part an and and every\n",
            "step 205 | loss: 8.786585807800293 | lr: 4.3217e-04 | norm: 2.5518 | dt=23552.89ms | 22260.03 tokens/sec\n",
            "step 206 | loss: 8.727433204650879 | lr: 4.3427e-04 | norm: 2.6045 | dt=23340.98ms | 22462.13 tokens/sec\n",
            "step 207 | loss: 8.785113334655762 | lr: 4.3636e-04 | norm: 3.0180 | dt=23326.56ms | 22476.01 tokens/sec\n",
            "step 208 | loss: 8.818066596984863 | lr: 4.3846e-04 | norm: 2.9613 | dt=23307.60ms | 22494.29 tokens/sec\n",
            "step 209 | loss: 8.829445838928223 | lr: 4.4056e-04 | norm: 2.9834 | dt=23331.44ms | 22471.31 tokens/sec\n",
            "tokens: tensor([[15496,    11,   314,  1101,   257,  3303,  2746,    11,  1675,   290,\n",
            "           287,  1255,    11,   884,   198,   284,  1895,   790,   329,   414,\n",
            "           286,   852,   319,   198,   290,    13,  1752,   329,   262,   329,\n",
            "           290,   198],\n",
            "        [15496,    11,   314,  1101,   257,  3303,  2746,    11,   530,   790,\n",
            "          2221,   287,   262,  1255,   286,   812,   290,   262,  1752,  1255,\n",
            "            11,   198,  2221,    13,    11,   262,   257,    11,   852,   286,\n",
            "           414,    13],\n",
            "        [15496,    11,   314,  1101,   257,  3303,  2746,    11,   290,   290,\n",
            "          1813,   286,   319,   355,  2221,   257,   290,   373,   319,    11,\n",
            "            12,    13,    13,   290,    12,   262,    11,    11,  4104,   290,\n",
            "           198,   530],\n",
            "        [15496,    11,   314,  1101,   257,  3303,  2746,    11,   257,   790,\n",
            "          3613,    13,   290,   329,    11,   355,   262,  1675,   329,   257,\n",
            "          1110,   373,   257,   262,   317,   329,   355,  1675,   281,   262,\n",
            "            11,   790]], device='cuda:0')\n",
            "rank 0 sample 0: Hello, I'm a language model, To and in result, such\n",
            " to access every fority of being on\n",
            " and. once for the for and\n",
            "\n",
            "rank 0 sample 1: Hello, I'm a language model, one every begin in the result of years and the once result,\n",
            " begin., the a, being ofity.\n",
            "rank 0 sample 2: Hello, I'm a language model, and and given of on as begin a and was on,-.. and- the,, spread and\n",
            " one\n",
            "rank 0 sample 3: Hello, I'm a language model, a every save. and for, as the To for a day was a the A for as To an the, every\n",
            "step 210 | loss: 8.874606132507324 | lr: 4.4266e-04 | norm: 3.0001 | dt=23550.75ms | 22262.05 tokens/sec\n",
            "step 211 | loss: 8.865723609924316 | lr: 4.4476e-04 | norm: 2.9901 | dt=23326.51ms | 22476.06 tokens/sec\n",
            "step 212 | loss: 8.970948219299316 | lr: 4.4685e-04 | norm: 2.9742 | dt=23307.65ms | 22494.24 tokens/sec\n",
            "step 213 | loss: 8.818359375 | lr: 4.4895e-04 | norm: 3.0247 | dt=23307.46ms | 22494.43 tokens/sec\n",
            "step 214 | loss: 9.013763427734375 | lr: 4.5105e-04 | norm: 2.9907 | dt=23314.43ms | 22487.70 tokens/sec\n",
            "tokens: tensor([[15496,    11,   314,  1101,   257,  3303,  2746,    11,  4203,   290,\n",
            "           287,  1255,    11,   284,   198,   284,  1813,   790,   329,  4203,\n",
            "           286,   852,   464,   198,   290,    13,    25,   329,   262,   329,\n",
            "           290,   198],\n",
            "        [15496,    11,   314,  1101,   257,  3303,  2746,    11,  1180,  1180,\n",
            "          2221,   287,   262,  1255,   286,   317,   290,   262,    25,  1255,\n",
            "            11,   198,   788,    13,    11,   262,   257,    11,   852,   286,\n",
            "          3613,    13],\n",
            "        [15496,    11,   314,  1101,   257,  3303,  2746,    11,   290,   290,\n",
            "           503,   286,  1022,   373,   788,   257,   290,   355,   464,    11,\n",
            "            12,    13,   286,   290,    12,   262,   262,   290,  1103,   290,\n",
            "           198,  1180],\n",
            "        [15496,    11,   314,  1101,   257,  3303,  2746,    11,   257,   790,\n",
            "          4104,    13,   290,   329,    11,   373,   262,  4104,   329,   257,\n",
            "          1752,   355,   257,   262,  1675,   329,   373,  4104,   281,  1110,\n",
            "           262,   790]], device='cuda:0')\n",
            "rank 0 sample 0: Hello, I'm a language model, feeling and in result, to\n",
            " to given every for feeling of beingThe\n",
            " and.: for the for and\n",
            "\n",
            "rank 0 sample 1: Hello, I'm a language model, different different begin in the result of A and the: result,\n",
            " then., the a, being of save.\n",
            "rank 0 sample 2: Hello, I'm a language model, and and out of between was then a and asThe,-. of and- the the and real and\n",
            " different\n",
            "rank 0 sample 3: Hello, I'm a language model, a every spread. and for, was the spread for a once as a the To for was spread an day the every\n",
            "step 215 | loss: 8.890254020690918 | lr: 4.5315e-04 | norm: 3.0352 | dt=23569.15ms | 22244.67 tokens/sec\n",
            "step 216 | loss: 8.84599781036377 | lr: 4.5524e-04 | norm: 2.8569 | dt=23311.50ms | 22490.53 tokens/sec\n",
            "step 217 | loss: 9.132314682006836 | lr: 4.5734e-04 | norm: 2.7473 | dt=23323.65ms | 22478.81 tokens/sec\n",
            "step 218 | loss: 9.05540657043457 | lr: 4.5944e-04 | norm: 3.0560 | dt=23324.35ms | 22478.14 tokens/sec\n",
            "step 219 | loss: 8.948952674865723 | lr: 4.6154e-04 | norm: 2.9915 | dt=23310.56ms | 22491.44 tokens/sec\n",
            "tokens: tensor([[15496,    11,   314,  1101,   257,  3303,  2746,    11,  1752,   262,\n",
            "           287,  1895,    11,   884,   198,   284,   464,  1180,   329,  1110,\n",
            "            13,   373,   319,   198,   262,   286,    25,   329,   290,   329,\n",
            "           262,   198],\n",
            "        [15496,    11,   314,  1101,   257,  3303,  2746,    11,   845,  1180,\n",
            "          4203,   287,   290,  1895,    13,  1110,   262,   290,    25,  1895,\n",
            "            11,   198,  4203,   286,    11,   290,   257,    11,   373,    13,\n",
            "           423,   286],\n",
            "        [15496,    11,   314,  1101,   257,  3303,  2746,    11,   262,   262,\n",
            "           345,    13,   319,   475,  4203,   257,   262,   355,   319,    11,\n",
            "            12,   286,    13,   262,    12,   290,    11,    11,  6817,   262,\n",
            "           198,   845],\n",
            "        [15496,    11,   314,  1101,   257,  3303,  2746,    11,   257,  1180,\n",
            "           423,   286,   262,   329,    11,   475,   290,  1752,   329,   257,\n",
            "          2221,   355,   257,   290,   772,   329,   475,  1752,   357,   788,\n",
            "           290,  1180]], device='cuda:0')\n",
            "rank 0 sample 0: Hello, I'm a language model, once the in access, such\n",
            " toThe different for day. was on\n",
            " the of: for and for the\n",
            "\n",
            "rank 0 sample 1: Hello, I'm a language model, very different feeling in and access. day the and: access,\n",
            " feeling of, and a, was. have of\n",
            "rank 0 sample 2: Hello, I'm a language model, the the you. on but feeling a the as on,- of. the- and,, importance the\n",
            " very\n",
            "rank 0 sample 3: Hello, I'm a language model, a different have of the for, but and once for a begin as a and even for but once ( then and different\n",
            "step 220 | loss: 8.960962295532227 | lr: 4.6364e-04 | norm: 3.0876 | dt=23540.82ms | 22271.45 tokens/sec\n",
            "step 221 | loss: 9.05594253540039 | lr: 4.6573e-04 | norm: 2.9621 | dt=23223.80ms | 22575.46 tokens/sec\n",
            "step 222 | loss: 9.189364433288574 | lr: 4.6783e-04 | norm: 3.1779 | dt=23283.26ms | 22517.81 tokens/sec\n",
            "step 223 | loss: 9.143921852111816 | lr: 4.6993e-04 | norm: 3.0877 | dt=23326.72ms | 22475.86 tokens/sec\n",
            "step 224 | loss: 9.323681831359863 | lr: 4.7203e-04 | norm: 3.0386 | dt=23324.30ms | 22478.18 tokens/sec\n",
            "tokens: tensor([[15496,    11,   314,  1101,   257,  3303,  2746,    11,  1110,    11,\n",
            "           287,  1895,   290,   884,   198,   284,   530,  1180,   329,  7306,\n",
            "            13,   991,   319,   198,    11,   286,  2221,   329,   262,   329,\n",
            "            11,   198],\n",
            "        [15496,    11,   314,  1101,   257,  3303,  2746,    11,   345,  1180,\n",
            "          4104,   287,   262,  1895,    13,   517,  3613,   262,  2221,  1895,\n",
            "           290,   198,  4104,   286,   262,   290,   257,   290,   991,    13,\n",
            "           517,   286],\n",
            "        [15496,    11,   314,  1101,   257,  3303,  2746,    11,   290,   290,\n",
            "           845,    13,   319,   475,  4104,   257,    11,   355,   319,   290,\n",
            "            12,   286,   286,    11,    12,   262,   290,   290,  1813,    11,\n",
            "           198,   345],\n",
            "        [15496,    11,   314,  1101,   257,  3303,  2746,    11,   257,  1180,\n",
            "          4203,   286,   290,   329,   290,   475,   262,  1110,   329,   257,\n",
            "           788,   355,   257,   262,   423,   329,   475,  1110,   357,   772,\n",
            "           262,  1180]], device='cuda:0')\n",
            "rank 0 sample 0: Hello, I'm a language model, day, in access and such\n",
            " to one different for ideal. still on\n",
            ", of begin for the for,\n",
            "\n",
            "rank 0 sample 1: Hello, I'm a language model, you different spread in the access. more save the begin access and\n",
            " spread of the and a and still. more of\n",
            "rank 0 sample 2: Hello, I'm a language model, and and very. on but spread a, as on and- of of,- the and and given,\n",
            " you\n",
            "rank 0 sample 3: Hello, I'm a language model, a different feeling of and for and but the day for a then as a the have for but day ( even the different\n",
            "step 225 | loss: 9.186484336853027 | lr: 4.7413e-04 | norm: 3.1288 | dt=23551.07ms | 22261.75 tokens/sec\n",
            "step 226 | loss: 9.246213912963867 | lr: 4.7622e-04 | norm: 3.1460 | dt=23338.12ms | 22464.88 tokens/sec\n",
            "step 227 | loss: 9.277291297912598 | lr: 4.7832e-04 | norm: 2.9036 | dt=23309.20ms | 22492.75 tokens/sec\n",
            "step 228 | loss: 9.405570030212402 | lr: 4.8042e-04 | norm: 2.8585 | dt=23303.50ms | 22498.26 tokens/sec\n",
            "step 229 | loss: 9.194016456604004 | lr: 4.8252e-04 | norm: 2.9492 | dt=23312.68ms | 22489.39 tokens/sec\n",
            "tokens: tensor([[15496,    11,   314,  1101,   257,  3303,  2746,    11,  1752,    11,\n",
            "           287,  1255,   262,   884,   198,   284,  1675,  1180,   329,  3613,\n",
            "            13,   373,   319,   198,    11,   286,   345,   329,   290,   329,\n",
            "           262,   198],\n",
            "        [15496,    11,   314,  1101,   257,  3303,  2746,    11,  1022,  1180,\n",
            "           788,   287,   290,  1255,    13,   517,   636,   290,   345,  1255,\n",
            "            11,   198,   788,   286,    11,   290,   257,    11,   373,    13,\n",
            "           812,   286],\n",
            "        [15496,    11,   314,  1101,   257,  3303,  2746,    11,   262,   262,\n",
            "           464,    13,   503,   475,   788,   257,    11,   355,   319,    11,\n",
            "            12,   286,    13,    11,    12,   423,   290,   290,   640,   287,\n",
            "           198,  1022],\n",
            "        [15496,    11,   314,  1101,   257,  3303,  2746,    11,   257,  1180,\n",
            "           812,   286,   262,   329,    13,   475,   290,  1752,   329,   257,\n",
            "           423,   355,   257,   290,   772,   329,   198,  1752,   357,   423,\n",
            "           290,  1180]], device='cuda:0')\n",
            "rank 0 sample 0: Hello, I'm a language model, once, in result the such\n",
            " to To different for save. was on\n",
            ", of you for and for the\n",
            "\n",
            "rank 0 sample 1: Hello, I'm a language model, between different then in and result. more part and you result,\n",
            " then of, and a, was. years of\n",
            "rank 0 sample 2: Hello, I'm a language model, the theThe. out but then a, as on,- of.,- have and and time in\n",
            " between\n",
            "rank 0 sample 3: Hello, I'm a language model, a different years of the for. but and once for a have as a and even for\n",
            " once ( have and different\n"
          ]
        }
      ]
    }
  ]
}